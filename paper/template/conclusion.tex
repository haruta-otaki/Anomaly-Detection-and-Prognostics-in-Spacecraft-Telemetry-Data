
\section{Conclusions}
\label{sec:concl}

This paper presented an unsupervised ensemble approach for detecting anomalies in spacecraft telemetry data from the SMAP satellite. We demonstrated that combining One-Class SVM, Isolation Forest, and Local Outlier Factor through majority voting achieves superior performance compared to individual models, with average recall of 0.55 and F1 score of 0.21 across nine telemetry channels (Figure~\ref{fig:model_comparison}). Our preprocessing pipeline using overlapping temporal windows and MiniRocket feature transformation effectively captured complex patterns in multivariate time series data.

\begin{figure}[t]
\centering
\includegraphics[width=\linewidth]{figs/model_comparison.png}
\caption{Comprehensive comparison of individual models (One-Class SVM, Isolation Forest, Local Outlier Factor) versus ensemble approach across all telemetry channels. The ensemble method consistently outperforms individual models in both recall and F1 score, demonstrating the effectiveness of majority voting for anomaly detection.}
\label{fig:model_comparison}
\end{figure}

Key findings from our analysis reveal significant performance variation across telemetry channels, with channels containing higher anomaly rates (e.g., channel D at 22.6\%) generally achieving better recall than those with sparse anomalies (e.g., channel B at 1.5\%), as illustrated in Figure~\ref{fig:performance_heatmap}. The ensemble model demonstrated particular strength in detecting contextual anomalies by leveraging the complementary strengths of its constituent algorithms: One-Class SVM's boundary-based detection, Isolation Forest's partition-based isolation, and LOF's density-based outlier identification. Threshold optimisation focused on maximising recall proved essential, as missing critical spacecraft anomalies carries far greater operational risk than investigating false alarms.

\begin{figure}[t]
\centering
\includegraphics[width=0.8\linewidth]{figs/performance_heatmap.png}
\caption{Performance metrics heatmap showing precision, recall, F1 score, and false discovery rate across all telemetry channels. Warmer colours indicate better performance, revealing substantial variation in detection difficulty across different telemetry streams.}
\label{fig:performance_heatmap}
\end{figure}

A limitation of our approach is the use of labelled test data for threshold selection. Whilst this allowed systematic exploration of recall-precision trade-offs, deployment systems should determine thresholds using held-out validation sets or unsupervised criteria to avoid optimistic bias. Additionally, our channel-specific modelling approach, whilst recognising the distinct nature of different telemetry streams, does not exploit potential correlations between channels that might improve detection accuracy.

\subsection{Ethical Considerations and Broader Impacts}

Automated anomaly detection systems for spacecraft operations carry significant ethical responsibilities. False negatives—failing to detect genuine anomalies—could result in undetected system degradation, potentially leading to mission failure, loss of valuable scientific data, or in crewed missions, endangering human life. Our emphasis on optimising recall addresses this concern by prioritising detection sensitivity. However, excessive false positives impose operational burden on mission control teams, potentially leading to alarm fatigue where genuine warnings are dismissed amongst frequent false alerts.

The deployment of such systems must maintain human oversight, with detected anomalies serving as decision support rather than automated responses. Operators require transparency in understanding why anomalies are flagged, necessitating interpretable models or explanation mechanisms beyond the black-box predictions examined here. Furthermore, the training data's representativeness is crucial; anomalies not present in historical data may be missed, requiring continuous model updating and validation against emerging failure modes.

Broader impacts include potential applications beyond spacecraft to other critical infrastructure monitoring systems, including power grids, industrial processes, and medical devices, where similar trade-offs between sensitivity and specificity must be carefully balanced against operational constraints and safety requirements.

\subsection{Future Work}

There are several promising directions for continuing this work. First, the incorporation of deep learning architectures, such as Long Short-Term Memory networks (LSTM) or transformer models might better capture long-range temporal dependencies in telemetry streams. These approaches have demonstrated strong performance in time series anomaly detection, but require careful consideration of training data requirements and computational constraints for deployment.

Second, multi-channel correlation analysis can exploit relationships between telemetry streams to improve detection accuracy. Graph Neural Networks (GNNs) or attention mechanisms can model inter-channel dependencies, potentially identifying anomalies characterised by unusual correlation patterns rather than individual channel deviations.

Third, developing unsupervised or semi-supervised threshold selection methods would eliminate reliance on labelled test data, making the approach more suitable for deployment scenarios with limited anomaly examples. Techniques based on extreme value theory or anomaly score distributions could provide principled threshold selection.

Lastly, incorporating anomaly explanation and visualisation capabilities would enhance operator trust and enable more effective response to detected anomalies. Methods for identifying which temporal patterns or sensor dimensions contribute most to anomaly scores would support root cause analysis and system diagnosis.