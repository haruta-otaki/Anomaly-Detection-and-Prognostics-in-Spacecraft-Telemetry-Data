{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e2cfce4d-82c7-43cf-a818-594b73f5d325",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import necessary packages\n",
    "from pathlib import Path\n",
    "import os\n",
    "import ast\n",
    "import shutil\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.metrics import classification_report, confusion_matrix, ConfusionMatrixDisplay, precision_score, recall_score, f1_score\n",
    "from sklearn.svm import OneClassSVM\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "from sklearn.neighbors import LocalOutlierFactor\n",
    "from sktime.transformations.panel.rocket import (\n",
    "    MiniRocket,\n",
    "    MiniRocketMultivariate,\n",
    "    MiniRocketMultivariateVariable,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ecfa9908-f807-42be-b37c-be84a9b87ec1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#collection of dataset information for each telemetry data \n",
    "training_dfs = []\n",
    "test_dfs = []\n",
    "\n",
    "training_df = []\n",
    "test_df = []\n",
    "\n",
    "file_names = []\n",
    "\n",
    "label_df = pd.read_csv(\"labeled_anomalies.csv\")\n",
    "\n",
    "train_data_path = \"npy_train\" \n",
    "test_data_path = \"npy_test\" \n",
    "\n",
    "os.makedirs(\"raw_train\", exist_ok=True)\n",
    "os.makedirs(\"raw_test\", exist_ok=True)\n",
    "\n",
    "index = 0\n",
    "for root, _, files in os.walk(train_data_path):\n",
    "    for file in files:\n",
    "        example_path = os.path.join(root, file)\n",
    "        filename = Path(example_path).stem\n",
    "        \n",
    "        row_indices = label_df[label_df['chan_id'] == filename].index.tolist()\n",
    "        if not row_indices:\n",
    "            continue\n",
    "        spacecraft = label_df.loc[row_indices[0], 'spacecraft']\n",
    "        \n",
    "        if (spacecraft == \"SMAP\"): \n",
    "            data = np.load(example_path)\n",
    "            df = pd.DataFrame(data)\n",
    "            print(\"(train) df: \", filename, df.shape, \"index: \", index)\n",
    "            df.to_csv(f\"raw_train/{filename}.csv\", index=False)\n",
    "            training_dfs.append(df) \n",
    "            index += 1\n",
    "\n",
    "index = 0\n",
    "for root, _, files in os.walk(test_data_path):\n",
    "    for file in files:\n",
    "        example_path = os.path.join(root, file)\n",
    "        filename = Path(example_path).stem\n",
    "        \n",
    "        row_indices = label_df[label_df['chan_id'] == filename].index.tolist()\n",
    "        if not row_indices:\n",
    "            continue\n",
    "        spacecraft = label_df.loc[row_indices[0], 'spacecraft']\n",
    "        \n",
    "        if (spacecraft == \"SMAP\"): \n",
    "            data = np.load(example_path)\n",
    "            df = pd.DataFrame(data)\n",
    "            print(\"(test) df: \", filename, df.shape, \"index: \", index)\n",
    "            df.to_csv(f\"raw_test/{filename}.csv\", index=False)\n",
    "            test_dfs.append(df) \n",
    "            file_names.append(filename)\n",
    "            \n",
    "            index += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d49f058b-3a33-4b1a-a147-81c717e1645e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data():\n",
    "    training_dfs = {}\n",
    "    test_dfs = {}\n",
    "    file_names = {\"train\": {}, \"test\": {}}\n",
    "    label_df = pd.read_csv(\"labeled_anomalies.csv\")\n",
    "    train_data_path = \"raw_train\" \n",
    "    test_data_path = \"raw_test\" \n",
    "    \n",
    "    for root, _, files in os.walk(train_data_path):\n",
    "        for file in files:\n",
    "            example_path = os.path.join(root, file)\n",
    "            filename = Path(example_path).stem\n",
    "            df = pd.read_csv(example_path)\n",
    "            channel = filename[0]            \n",
    "            if (training_dfs.get(channel) == None):\n",
    "                training_dfs[channel] = []\n",
    "                file_names[\"train\"][channel] = []\n",
    "                training_dfs[channel].append(df)\n",
    "                file_names[\"train\"][channel].append(filename)\n",
    "            else:\n",
    "                training_dfs[channel].append(df)\n",
    "                file_names[\"train\"][channel].append(filename)\n",
    "    \n",
    "    for root, _, files in os.walk(test_data_path):\n",
    "        for file in files:\n",
    "            example_path = os.path.join(root, file)\n",
    "            filename = Path(example_path).stem\n",
    "            df = pd.read_csv(example_path)\n",
    "            channel = filename[0]\n",
    "            if (test_dfs.get(channel) == None):\n",
    "                test_dfs[channel] = []\n",
    "                file_names[\"test\"][channel] = []\n",
    "                test_dfs[channel].append(df)\n",
    "                file_names[\"test\"][channel].append(filename)\n",
    "            else:\n",
    "                test_dfs[channel].append(df)\n",
    "                file_names[\"test\"][channel].append(filename)\n",
    "\n",
    "    return (training_dfs, test_dfs, label_df, file_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b7af7343-fd52-45db-9b3a-0cf2358da275",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_windows(training_dfs, test_dfs, window_size, window_overlap, label_df, file_names):\n",
    "    training_data = {}\n",
    "    test_data = {}\n",
    "    label_data = {}\n",
    "    \n",
    "    for channel in training_dfs.keys():\n",
    "        training_data[channel] = []\n",
    "        for df in training_dfs[channel]: \n",
    "            for i in range(0, len(df), window_overlap):\n",
    "                window = []\n",
    "                if i + window_size > len(df): \n",
    "                    window = df.iloc[-window_size:].to_numpy().tolist()\n",
    "                else: \n",
    "                    window = df.iloc[i:i + window_size].to_numpy().tolist()\n",
    "                np_window = np.array(window)\n",
    "                transposed_window = np_window.T\n",
    "                normal_window = transposed_window.tolist() \n",
    "                training_data[channel].append(normal_window)\n",
    "                \n",
    "    for channel in test_dfs.keys():\n",
    "        test_data[channel] = []\n",
    "        label_data[channel] = []\n",
    "        for i in range(len(test_dfs[channel])):\n",
    "            df = test_dfs[channel][i]\n",
    "            for j in range(0, len(df), window_overlap):\n",
    "                window = []\n",
    "                if j + window_size > len(df): \n",
    "                    window = df.iloc[-window_size:].to_numpy().tolist()\n",
    "                else: \n",
    "                    window = df.iloc[j:j + window_size].to_numpy().tolist()\n",
    "                row_indices = label_df[label_df[\"chan_id\"] == file_names[\"test\"][channel][i]].index.tolist()\n",
    "                \n",
    "                if not row_indices:\n",
    "                    continue\n",
    "\n",
    "                anomaly_sequence = label_df.loc[row_indices[0], 'anomaly_sequences']\n",
    "                anomaly_sequence = ast.literal_eval(anomaly_sequence)\n",
    "                labeled = False\n",
    "                for anomalies in anomaly_sequence:\n",
    "                    if (not(anomalies[1] <= j or anomalies[0] >= j + window_size)) and labeled == False:\n",
    "                        label_data[channel].append(1)\n",
    "                        labeled = True\n",
    "                if labeled == False:\n",
    "                    label_data[channel].append(0)\n",
    "                np_window = np.array(window)\n",
    "                transposed_window = np_window.T\n",
    "                normal_window = transposed_window.tolist() \n",
    "                test_data[channel].append(normal_window)\n",
    "                \n",
    "    return (training_data, test_data, label_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1d0c50c2-a610-488e-8e78-a346d393de6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train:  A shape:  (842, 25, 60)\n",
      "train:  P shape:  (703, 25, 60)\n",
      "train:  F shape:  (432, 25, 60)\n",
      "train:  D shape:  (1445, 25, 60)\n",
      "train:  R shape:  (144, 25, 60)\n",
      "train:  G shape:  (793, 25, 60)\n",
      "train:  T shape:  (431, 25, 60)\n",
      "train:  E shape:  (1867, 25, 60)\n",
      "train:  S shape:  (141, 25, 60)\n",
      "train:  B shape:  (122, 25, 60)\n",
      "test:  E shape:  (5486, 25, 60)\n",
      "test:  T shape:  (1292, 25, 60)\n",
      "test:  G shape:  (2405, 25, 60)\n",
      "test:  D shape:  (4789, 25, 60)\n",
      "test:  A shape:  (3374, 25, 60)\n",
      "test:  F shape:  (1281, 25, 60)\n",
      "test:  P shape:  (2056, 25, 60)\n",
      "test:  B shape:  (403, 25, 60)\n",
      "test:  R shape:  (363, 25, 60)\n",
      "test:  S shape:  (367, 25, 60)\n",
      "label:  E shape:  (5486,)\n",
      "label:  T shape:  (1292,)\n",
      "label:  G shape:  (2405,)\n",
      "label:  D shape:  (4789,)\n",
      "label:  A shape:  (3374,)\n",
      "label:  F shape:  (1281,)\n",
      "label:  P shape:  (2056,)\n",
      "label:  B shape:  (403,)\n",
      "label:  R shape:  (363,)\n",
      "label:  S shape:  (367,)\n"
     ]
    }
   ],
   "source": [
    "window_size = 60 \n",
    "window_overlap = 20\n",
    "training_dfs, test_dfs, label_df, file_names = get_data()\n",
    "\n",
    "X_train_collection, X_test_collection, y_test_collection = create_windows(training_dfs, test_dfs, window_size, window_overlap, label_df, file_names)\n",
    "\n",
    "data = {}\n",
    "os.makedirs(\"data\", exist_ok=True)\n",
    "\n",
    "for channel in X_train_collection:\n",
    "    if data.get(channel) is None:\n",
    "        data[channel] = {}\n",
    "    if data.get(channel).get(\"train\") is None:\n",
    "        X_train = np.array(X_train_collection[channel])\n",
    "        path = f\"data/{channel}/train\"\n",
    "        os.makedirs(path, exist_ok=True)\n",
    "        np.save(path + f\"/{channel}.npy\", X_train)\n",
    "        data[channel][\"train\"] = path + f\"/{channel}.npy\"\n",
    "        print(\"train: \", channel, \"shape: \", X_train.shape)\n",
    "    else:\n",
    "        print(\"Error: duplicate training data sets\")\n",
    "   \n",
    "    \n",
    "for channel in X_test_collection: \n",
    "    if data.get(channel) is None:\n",
    "        continue\n",
    "    if data.get(channel).get(\"test\") is None:\n",
    "        X_test = np.array(X_test_collection[channel])\n",
    "        path = f\"data/{channel}/test\"\n",
    "        os.makedirs(path, exist_ok=True)\n",
    "        np.save(path + f\"/{channel}.npy\", X_test)\n",
    "        data[channel][\"test\"] = path + f\"/{channel}.npy\"\n",
    "        print(\"test: \", channel, \"shape: \", X_test.shape)\n",
    "    else:\n",
    "        print(\"Error: duplicate testing data sets\")\n",
    "   \n",
    "  \n",
    "for channel in y_test_collection:\n",
    "    if data.get(channel) is None:\n",
    "        continue\n",
    "    if data.get(channel).get(\"label\") is None:\n",
    "        y_test = np.array(y_test_collection[channel])\n",
    "        path = f\"data/{channel}/label\"\n",
    "        os.makedirs(path, exist_ok=True)\n",
    "        np.save(path + f\"/{channel}.npy\", y_test)\n",
    "        data[channel][\"label\"] = path + f\"/{channel}.npy\"\n",
    "        print(\"label: \", channel, \"shape: \", y_test.shape)\n",
    "    else:\n",
    "        print(\"Error: duplicate label data sets\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b62abdbd-26c4-4901-b050-32642e436af7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['T', 'G', 'S', 'P', 'D', 'F', 'R', 'A', 'E', 'B']\n"
     ]
    }
   ],
   "source": [
    "channel_names = []\n",
    "\n",
    "for channel in os.listdir(\"data\"):\n",
    "    if os.path.isdir(os.path.join(\"data\", channel)):\n",
    "        channel_names.append(channel)\n",
    "print(channel_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8916e30a-ea28-467c-a281-986881bd9da8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/DAVIDSON/haotaki/.local/lib/python3.10/site-packages/numba/np/ufunc/parallel.py:373: NumbaWarning: \u001b[1mThe TBB threading layer requires TBB version 2021 update 6 or later i.e., TBB_INTERFACE_VERSION >= 12060. Found TBB_INTERFACE_VERSION = 12050. The TBB threading layer is disabled.\u001b[0m\n",
      "  warnings.warn(problem)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train:  T shape:  (431, 9996)\n",
      "test:  T shape:  (1292, 9996)\n",
      "label:  T shape:  (1292,)\n",
      "train:  G shape:  (793, 9996)\n",
      "test:  G shape:  (2405, 9996)\n",
      "label:  G shape:  (2405,)\n",
      "train:  S shape:  (141, 9996)\n",
      "test:  S shape:  (367, 9996)\n",
      "label:  S shape:  (367,)\n",
      "train:  P shape:  (703, 9996)\n",
      "test:  P shape:  (2056, 9996)\n",
      "label:  P shape:  (2056,)\n",
      "train:  D shape:  (1445, 9996)\n",
      "test:  D shape:  (4789, 9996)\n",
      "label:  D shape:  (4789,)\n",
      "train:  F shape:  (432, 9996)\n",
      "test:  F shape:  (1281, 9996)\n",
      "label:  F shape:  (1281,)\n",
      "train:  R shape:  (144, 9996)\n",
      "test:  R shape:  (363, 9996)\n",
      "label:  R shape:  (363,)\n",
      "train:  A shape:  (842, 9996)\n",
      "test:  A shape:  (3374, 9996)\n",
      "label:  A shape:  (3374,)\n",
      "train:  E shape:  (1867, 9996)\n",
      "test:  E shape:  (5486, 9996)\n",
      "label:  E shape:  (5486,)\n",
      "train:  B shape:  (122, 9996)\n",
      "test:  B shape:  (403, 9996)\n",
      "label:  B shape:  (403,)\n"
     ]
    }
   ],
   "source": [
    "transformed_data= {}\n",
    "for channel in channel_names:\n",
    "    transformed_data[channel] = {}\n",
    "    training_data_path = f\"data/{channel}/train/{channel}.npy\"\n",
    "    testing_data_path = f\"data/{channel}/test/{channel}.npy\"\n",
    "    label_data_path = f\"data/{channel}/label/{channel}.npy\"\n",
    "    \n",
    "    X_train = np.load(training_data_path)\n",
    "    X_test = np.load(testing_data_path)\n",
    "    y_test = np.load(label_data_path)\n",
    "\n",
    "    minirocket = MiniRocketMultivariate(n_jobs = 2, random_state = 42) \n",
    "    minirocket.fit(X_train)\n",
    "    X_transform_train = minirocket.transform(X_train)\n",
    "    X_transform_test = minirocket.transform(X_test)\n",
    "\n",
    "    transformed_data[channel][\"train\"] = X_transform_train\n",
    "    print(\"train: \", channel, \"shape: \", X_transform_train.shape)\n",
    "    transformed_data[channel][\"test\"] = X_transform_test\n",
    "    print(\"test: \", channel, \"shape: \", X_transform_test.shape)\n",
    "    transformed_data[channel][\"label\"] = y_test\n",
    "    print(\"label: \", channel, \"shape: \", y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e38d02f6-6973-4871-b93e-2e7fcba2727b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train:  T shape:  (431, 9996)\n",
      "test:  T shape:  (1292, 9996)\n",
      "label:  T shape:  (1292,)\n",
      "train:  G shape:  (793, 9996)\n",
      "test:  G shape:  (2405, 9996)\n",
      "label:  G shape:  (2405,)\n",
      "train:  S shape:  (141, 9996)\n",
      "test:  S shape:  (367, 9996)\n",
      "label:  S shape:  (367,)\n",
      "train:  P shape:  (703, 9996)\n",
      "test:  P shape:  (2056, 9996)\n",
      "label:  P shape:  (2056,)\n",
      "train:  D shape:  (1445, 9996)\n",
      "test:  D shape:  (4789, 9996)\n",
      "label:  D shape:  (4789,)\n",
      "train:  F shape:  (432, 9996)\n",
      "test:  F shape:  (1281, 9996)\n",
      "label:  F shape:  (1281,)\n",
      "train:  R shape:  (144, 9996)\n",
      "test:  R shape:  (363, 9996)\n",
      "label:  R shape:  (363,)\n",
      "train:  A shape:  (842, 9996)\n",
      "test:  A shape:  (3374, 9996)\n",
      "label:  A shape:  (3374,)\n",
      "train:  E shape:  (1867, 9996)\n",
      "test:  E shape:  (5486, 9996)\n",
      "label:  E shape:  (5486,)\n",
      "train:  B shape:  (122, 9996)\n",
      "test:  B shape:  (403, 9996)\n",
      "label:  B shape:  (403,)\n"
     ]
    }
   ],
   "source": [
    "fitted_data = {}\n",
    "\n",
    "for channel in transformed_data: \n",
    "    fitted_data[channel] = {}\n",
    "    X_transform_train = transformed_data[channel][\"train\"]\n",
    "    X_transform_test = transformed_data[channel][\"test\"]\n",
    "    scaler = MinMaxScaler()\n",
    "    scaler.fit(X_transform_train)\n",
    "    X_fit_train = scaler.transform(X_transform_train)\n",
    "    X_fit_test = scaler.transform(X_transform_test)\n",
    "    \n",
    "    fitted_data[channel][\"train\"] = X_fit_train\n",
    "    fitted_data[channel][\"test\"] = X_fit_test\n",
    "    fitted_data[channel][\"label\"] = transformed_data[channel][\"label\"]\n",
    "    print(\"train: \", channel, \"shape: \", X_fit_train.shape)\n",
    "    print(\"test: \", channel, \"shape: \", X_fit_test.shape)\n",
    "    print(\"label: \", channel, \"shape: \", transformed_data[channel][\"label\"].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "d722ab9f-a61f-4f36-8347-a54434153f8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.14628482972136223, 0.021205821205821207, 0.0681198910081744, 0.14348249027237353, 0.22635205679682607, 0.12724434035909446, 0.01928374655647383, 0.16478956727919383, 0.11009843237331389, 0.01488833746898263]\n"
     ]
    }
   ],
   "source": [
    "# performance bad for channels B, R, and S due to their small training data size\n",
    "# nu - controls boundary tightness (Smaller nu → tighter boundary → fewer false positives, Larger nu → looser boundary → higher recall)\n",
    "# threshold\t- converts scores (anomaly / normal)\n",
    "\n",
    "# Large (1000+ windows/channel)\tMostly clean\t0.01 – 0.02\n",
    "# Medium (hundreds of windows)\tMostly clean\t0.02 – 0.05\n",
    "# Small or noisy\tSome anomalies in training\t0.05 – 0.1\n",
    "#tighter nu makes more sense as the training data is supposed to have only normal data - needs confirmation at this point in time \n",
    "\n",
    "anomaly_rate = []\n",
    "for channel in transformed_data: \n",
    "    anomaly_count = 0\n",
    "    for label in fitted_data[channel][\"label\"]:\n",
    "        if label == 1:\n",
    "            anomaly_count += 1\n",
    "    anomaly_rate.append(anomaly_count / len(fitted_data[channel][\"label\"]))\n",
    "    \n",
    "print(anomaly_rate)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "183b7ba3-ab8b-4f27-af59-6786a12b5141",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(threshold, decision_scores):\n",
    "    y_pred = []\n",
    "    for score in decision_scores: \n",
    "        if score < threshold: \n",
    "            y_pred.append(1)\n",
    "        else:\n",
    "            y_pred.append(0)\n",
    "    return np.array(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c299bcd5-4795-4e06-a8de-cf0c38e70a35",
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_class_svm(channel_data, channel):\n",
    "    print(\"channel:\", channel)\n",
    "    clf = OneClassSVM().fit(channel_data[\"train\"])\n",
    "    decision_scores = clf.decision_function(channel_data[\"test\"])\n",
    "    \n",
    "    thresholds = []\n",
    "    for score in decision_scores: \n",
    "        if score < 0:\n",
    "            thresholds.append(score)\n",
    "    \n",
    "    best_f1_score = 0\n",
    "    best_recall_score = 0\n",
    "    best_thresholds = []\n",
    "    best_threshold = 0\n",
    "\n",
    "    # for th in thresholds:\n",
    "    #     y_pred = predict(th, decision_scores)\n",
    "    #     f1 = f1_score(channel_data[\"label\"], y_pred)\n",
    "    #     if (best_f1_score <= f1):\n",
    "    #         best_f1_score = f1\n",
    "    #         best_threshold = th\n",
    "\n",
    "    for th in thresholds:\n",
    "        y_pred = predict(th, decision_scores)\n",
    "        f1 = f1_score(channel_data[\"label\"], y_pred)\n",
    "        recall = recall_score(channel_data[\"label\"], y_pred)\n",
    "        if (best_recall_score <= recall):\n",
    "            best_recall_score = recall\n",
    "            best_thresholds.append(th) \n",
    "    \n",
    "    for th in best_thresholds:\n",
    "        y_pred = predict(th, decision_scores)\n",
    "        f1 = f1_score(channel_data[\"label\"], y_pred)\n",
    "        if (best_f1_score <= f1):\n",
    "            best_f1_score = f1\n",
    "            best_threshold = th\n",
    "    \n",
    "    y_test = channel_data[\"label\"]\n",
    "    y_pred = predict(best_threshold, decision_scores)\n",
    "    print(\"best_threshold: \", best_threshold)\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    precision = precision_score(y_test, y_pred, average='weighted')\n",
    "    print(\"FDR:\", 1 - precision)\n",
    "    c_m = confusion_matrix(y_test, y_pred)\n",
    "    print(c_m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "207f134b-c3af-4e7b-9e60-df31cec0c957",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "channel: T\n",
      "best_threshold:  -0.027457979179303038\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.59      0.68      1103\n",
      "           1       0.09      0.25      0.14       189\n",
      "\n",
      "    accuracy                           0.54      1292\n",
      "   macro avg       0.46      0.42      0.41      1292\n",
      "weighted avg       0.71      0.54      0.60      1292\n",
      "\n",
      "FDR: 0.2864852626864265\n",
      "[[646 457]\n",
      " [142  47]]\n",
      "channel: G\n",
      "best_threshold:  -5.657644072881624\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.76      0.86      2354\n",
      "           1       0.04      0.45      0.07        51\n",
      "\n",
      "    accuracy                           0.76      2405\n",
      "   macro avg       0.51      0.61      0.47      2405\n",
      "weighted avg       0.96      0.76      0.84      2405\n",
      "\n",
      "FDR: 0.03535299951608539\n",
      "[[1800  554]\n",
      " [  28   23]]\n",
      "channel: S\n",
      "best_threshold:  -0.2859636559503791\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.56      0.71       342\n",
      "           1       0.12      0.84      0.21        25\n",
      "\n",
      "    accuracy                           0.58       367\n",
      "   macro avg       0.55      0.70      0.46       367\n",
      "weighted avg       0.92      0.58      0.68       367\n",
      "\n",
      "FDR: 0.07891841698634683\n",
      "[[191 151]\n",
      " [  4  21]]\n",
      "channel: P\n",
      "best_threshold:  -0.09215555038088041\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.35      0.50      1761\n",
      "           1       0.16      0.74      0.26       295\n",
      "\n",
      "    accuracy                           0.40      2056\n",
      "   macro avg       0.52      0.54      0.38      2056\n",
      "weighted avg       0.78      0.40      0.47      2056\n",
      "\n",
      "FDR: 0.2171996116105841\n",
      "[[ 614 1147]\n",
      " [  78  217]]\n",
      "channel: D\n",
      "best_threshold:  -0.0829721582074967\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.60      0.70      3705\n",
      "           1       0.32      0.65      0.43      1084\n",
      "\n",
      "    accuracy                           0.61      4789\n",
      "   macro avg       0.59      0.62      0.56      4789\n",
      "weighted avg       0.73      0.61      0.64      4789\n",
      "\n",
      "FDR: 0.2679499960497369\n",
      "[[2207 1498]\n",
      " [ 381  703]]\n",
      "channel: F\n",
      "best_threshold:  -0.013036751453412876\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.13      0.23      1118\n",
      "           1       0.12      0.82      0.21       163\n",
      "\n",
      "    accuracy                           0.22      1281\n",
      "   macro avg       0.48      0.48      0.22      1281\n",
      "weighted avg       0.74      0.22      0.23      1281\n",
      "\n",
      "FDR: 0.25562013524887206\n",
      "[[147 971]\n",
      " [ 29 134]]\n",
      "channel: R\n",
      "best_threshold:  -23.521180814238708\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.94      0.96       356\n",
      "           1       0.12      0.43      0.19         7\n",
      "\n",
      "    accuracy                           0.93       363\n",
      "   macro avg       0.55      0.68      0.58       363\n",
      "weighted avg       0.97      0.93      0.95       363\n",
      "\n",
      "FDR: 0.028575806477904475\n",
      "[[334  22]\n",
      " [  4   3]]\n",
      "channel: A\n",
      "best_threshold:  -0.00020501814049112\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.41      0.54      2818\n",
      "           1       0.13      0.44      0.20       556\n",
      "\n",
      "    accuracy                           0.41      3374\n",
      "   macro avg       0.46      0.42      0.37      3374\n",
      "weighted avg       0.68      0.41      0.48      3374\n",
      "\n",
      "FDR: 0.321999098421203\n",
      "[[1150 1668]\n",
      " [ 312  244]]\n",
      "channel: E\n",
      "best_threshold:  -3.755458027391512\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.51      0.66      4882\n",
      "           1       0.18      0.85      0.29       604\n",
      "\n",
      "    accuracy                           0.55      5486\n",
      "   macro avg       0.57      0.68      0.48      5486\n",
      "weighted avg       0.88      0.55      0.62      5486\n",
      "\n",
      "FDR: 0.12156471090219012\n",
      "[[2476 2406]\n",
      " [  89  515]]\n",
      "channel: B\n",
      "best_threshold:  -1.6053533613558102e-08\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.57      0.72       397\n",
      "           1       0.03      1.00      0.07         6\n",
      "\n",
      "    accuracy                           0.57       403\n",
      "   macro avg       0.52      0.78      0.39       403\n",
      "weighted avg       0.99      0.57      0.71       403\n",
      "\n",
      "FDR: 0.014386483396994443\n",
      "[[225 172]\n",
      " [  0   6]]\n"
     ]
    }
   ],
   "source": [
    "for channel in fitted_data:\n",
    "    one_class_svm(fitted_data[channel], channel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "39100882-1db0-41d8-a761-c0f45e196a1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(threshold, decision_scores):\n",
    "    y_pred = []\n",
    "    for score in decision_scores: \n",
    "        if score < threshold: \n",
    "            y_pred.append(1)\n",
    "        else:\n",
    "            y_pred.append(0)\n",
    "    return np.array(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "36fafb8e-9f0e-4cd6-b18d-d1b4902bda29",
   "metadata": {},
   "outputs": [],
   "source": [
    "def isolation_forest_manual(channel_data, channel):\n",
    "    print(\"channel:\", channel)\n",
    "    clf = IsolationForest(random_state=42, n_jobs=-1).fit(channel_data[\"train\"])\n",
    "    decision_scores = clf.decision_function(channel_data[\"test\"])\n",
    "    \n",
    "    thresholds = []\n",
    "    for score in decision_scores: \n",
    "        if score < 0:\n",
    "            thresholds.append(score)\n",
    "    \n",
    "    best_f1_score = 0\n",
    "    best_recall_score = 0\n",
    "    best_thresholds = []\n",
    "    best_threshold = 0\n",
    "\n",
    "    # for th in thresholds:\n",
    "    #     y_pred = predict(th, decision_scores)\n",
    "    #     f1 = f1_score(channel_data[\"label\"], y_pred)\n",
    "    #     if (best_f1_score <= f1):\n",
    "    #         best_f1_score = f1\n",
    "    #         best_threshold = th\n",
    "\n",
    "    for th in thresholds:\n",
    "        y_pred = predict(th, decision_scores)\n",
    "        f1 = f1_score(channel_data[\"label\"], y_pred)\n",
    "        recall = recall_score(channel_data[\"label\"], y_pred)\n",
    "        if (best_recall_score <= recall):\n",
    "            best_recall_score = recall\n",
    "            best_thresholds.append(th) \n",
    "    \n",
    "    for th in best_thresholds:\n",
    "        y_pred = predict(th, decision_scores)\n",
    "        f1 = f1_score(channel_data[\"label\"], y_pred)\n",
    "        if (best_f1_score <= f1):\n",
    "            best_f1_score = f1\n",
    "            best_threshold = th\n",
    "    \n",
    "    y_test = channel_data[\"label\"]\n",
    "    y_pred = predict(best_threshold, decision_scores)\n",
    "    # raw_y_pred = clf.predict(channel_data[\"test\"])\n",
    "    # y_pred = []\n",
    "    # for y in raw_y_pred:\n",
    "    #     if y == -1:\n",
    "    #         y_pred.append(1)\n",
    "    #     else:\n",
    "    #         y_pred.append(0)\n",
    "            \n",
    "    print(\"best_threshold: \", best_threshold)\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    precision = precision_score(y_test, y_pred, average='weighted')\n",
    "    print(\"FDR:\", 1 - precision)\n",
    "    c_m = confusion_matrix(y_test, y_pred)\n",
    "    print(c_m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "b7003185-2129-4e99-8fa6-bd5323a3b1e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "channel: T\n",
      "best_threshold:  -0.01929036069550194\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.95      0.90      1103\n",
      "           1       0.00      0.00      0.00       189\n",
      "\n",
      "    accuracy                           0.81      1292\n",
      "   macro avg       0.42      0.48      0.45      1292\n",
      "weighted avg       0.72      0.81      0.77      1292\n",
      "\n",
      "FDR: 0.2765125675604765\n",
      "[[1050   53]\n",
      " [ 189    0]]\n",
      "channel: G\n",
      "best_threshold:  -0.005050661083903396\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.87      0.92      2354\n",
      "           1       0.02      0.10      0.03        51\n",
      "\n",
      "    accuracy                           0.85      2405\n",
      "   macro avg       0.50      0.48      0.47      2405\n",
      "weighted avg       0.96      0.85      0.90      2405\n",
      "\n",
      "FDR: 0.04243481781826175\n",
      "[[2042  312]\n",
      " [  46    5]]\n",
      "channel: S\n",
      "best_threshold:  -0.008187031232122943\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.94      0.94       342\n",
      "           1       0.05      0.04      0.04        25\n",
      "\n",
      "    accuracy                           0.88       367\n",
      "   macro avg       0.49      0.49      0.49       367\n",
      "weighted avg       0.87      0.88      0.88       367\n",
      "\n",
      "FDR: 0.12951516937908691\n",
      "[[322  20]\n",
      " [ 24   1]]\n",
      "channel: P\n",
      "best_threshold:  -0.007819392890866195\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.95      0.90      1761\n",
      "           1       0.11      0.04      0.06       295\n",
      "\n",
      "    accuracy                           0.82      2056\n",
      "   macro avg       0.48      0.49      0.48      2056\n",
      "weighted avg       0.75      0.82      0.78      2056\n",
      "\n",
      "FDR: 0.2519724632489695\n",
      "[[1665   96]\n",
      " [ 283   12]]\n",
      "channel: D\n",
      "best_threshold:  -0.0005285612921521743\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.90      0.83      3705\n",
      "           1       0.22      0.10      0.13      1084\n",
      "\n",
      "    accuracy                           0.72      4789\n",
      "   macro avg       0.49      0.50      0.48      4789\n",
      "weighted avg       0.65      0.72      0.67      4789\n",
      "\n",
      "FDR: 0.35332415019562724\n",
      "[[3325  380]\n",
      " [ 979  105]]\n",
      "channel: F\n",
      "best_threshold:  -0.06160470474137503\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.99      0.93      1118\n",
      "           1       0.25      0.02      0.04       163\n",
      "\n",
      "    accuracy                           0.87      1281\n",
      "   macro avg       0.56      0.51      0.49      1281\n",
      "weighted avg       0.79      0.87      0.82      1281\n",
      "\n",
      "FDR: 0.20513139746924502\n",
      "[[1106   12]\n",
      " [ 159    4]]\n",
      "channel: R\n",
      "best_threshold:  -0.08074729147369086\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.95      0.97       356\n",
      "           1       0.00      0.00      0.00         7\n",
      "\n",
      "    accuracy                           0.93       363\n",
      "   macro avg       0.49      0.48      0.48       363\n",
      "weighted avg       0.96      0.93      0.95       363\n",
      "\n",
      "FDR: 0.03912482682845264\n",
      "[[339  17]\n",
      " [  7   0]]\n",
      "channel: A\n",
      "best_threshold:  -0.004590622411925871\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.91      0.86      2818\n",
      "           1       0.01      0.00      0.00       556\n",
      "\n",
      "    accuracy                           0.76      3374\n",
      "   macro avg       0.41      0.46      0.43      3374\n",
      "weighted avg       0.69      0.76      0.72      3374\n",
      "\n",
      "FDR: 0.31200589633648046\n",
      "[[2562  256]\n",
      " [ 554    2]]\n",
      "channel: E\n",
      "best_threshold:  -0.0025550536830118986\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.93      0.91      4882\n",
      "           1       0.13      0.09      0.11       604\n",
      "\n",
      "    accuracy                           0.83      5486\n",
      "   macro avg       0.51      0.51      0.51      5486\n",
      "weighted avg       0.81      0.83      0.82      5486\n",
      "\n",
      "FDR: 0.19174155065766096\n",
      "[[4524  358]\n",
      " [ 549   55]]\n",
      "channel: B\n",
      "best_threshold:  -0.13213907805670955\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.98      0.98       397\n",
      "           1       0.00      0.00      0.00         6\n",
      "\n",
      "    accuracy                           0.96       403\n",
      "   macro avg       0.49      0.49      0.49       403\n",
      "weighted avg       0.97      0.96      0.97       403\n",
      "\n",
      "FDR: 0.02989003791361744\n",
      "[[388   9]\n",
      " [  6   0]]\n"
     ]
    }
   ],
   "source": [
    "for channel in fitted_data:\n",
    "    isolation_forest_manual(fitted_data[channel], channel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "99a10b2c-f5b1-4457-9ab5-fe31c91253b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def isolation_forest_default(channel_data, channel):\n",
    "    print(\"channel:\", channel)\n",
    "    clf = IsolationForest(random_state=42, n_jobs=-1).fit(channel_data[\"train\"])\n",
    "    y_test = channel_data[\"label\"]\n",
    "    raw_y_pred = clf.predict(channel_data[\"test\"])\n",
    "    y_pred = []\n",
    "    for y in raw_y_pred:\n",
    "        if y == -1:\n",
    "            y_pred.append(1)\n",
    "        else:\n",
    "            y_pred.append(0)\n",
    "            \n",
    "    print(classification_report(y_test, y_pred))\n",
    "    precision = precision_score(y_test, y_pred, average='weighted')\n",
    "    print(\"FDR:\", 1 - precision)\n",
    "    c_m = confusion_matrix(y_test, y_pred)\n",
    "    print(c_m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "b35845d8-e200-4709-8440-4ce26fc5e68a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "channel: T\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.95      0.90      1103\n",
      "           1       0.00      0.00      0.00       189\n",
      "\n",
      "    accuracy                           0.81      1292\n",
      "   macro avg       0.42      0.48      0.45      1292\n",
      "weighted avg       0.72      0.81      0.77      1292\n",
      "\n",
      "FDR: 0.27661775959427215\n",
      "[[1049   54]\n",
      " [ 189    0]]\n",
      "channel: G\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.84      0.91      2354\n",
      "           1       0.01      0.10      0.02        51\n",
      "\n",
      "    accuracy                           0.83      2405\n",
      "   macro avg       0.50      0.47      0.46      2405\n",
      "weighted avg       0.96      0.83      0.89      2405\n",
      "\n",
      "FDR: 0.0430909729284914\n",
      "[[1985  369]\n",
      " [  46    5]]\n",
      "channel: S\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.91      0.92       342\n",
      "           1       0.03      0.04      0.04        25\n",
      "\n",
      "    accuracy                           0.85       367\n",
      "   macro avg       0.48      0.47      0.48       367\n",
      "weighted avg       0.87      0.85      0.86       367\n",
      "\n",
      "FDR: 0.13275270446134446\n",
      "[[311  31]\n",
      " [ 24   1]]\n",
      "channel: P\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.93      0.89      1761\n",
      "           1       0.09      0.04      0.06       295\n",
      "\n",
      "    accuracy                           0.81      2056\n",
      "   macro avg       0.47      0.49      0.47      2056\n",
      "weighted avg       0.74      0.81      0.77      2056\n",
      "\n",
      "FDR: 0.2555831794316038\n",
      "[[1646  115]\n",
      " [ 283   12]]\n",
      "channel: D\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.90      0.83      3705\n",
      "           1       0.22      0.10      0.13      1084\n",
      "\n",
      "    accuracy                           0.72      4789\n",
      "   macro avg       0.49      0.50      0.48      4789\n",
      "weighted avg       0.65      0.72      0.67      4789\n",
      "\n",
      "FDR: 0.3537481501336178\n",
      "[[3322  383]\n",
      " [ 979  105]]\n",
      "channel: F\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.94      0.90      1118\n",
      "           1       0.05      0.02      0.03       163\n",
      "\n",
      "    accuracy                           0.82      1281\n",
      "   macro avg       0.46      0.48      0.47      1281\n",
      "weighted avg       0.76      0.82      0.79      1281\n",
      "\n",
      "FDR: 0.23552277643787312\n",
      "[[1047   71]\n",
      " [ 159    4]]\n",
      "channel: R\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.94      0.96       356\n",
      "           1       0.00      0.00      0.00         7\n",
      "\n",
      "    accuracy                           0.92       363\n",
      "   macro avg       0.49      0.47      0.48       363\n",
      "weighted avg       0.96      0.92      0.94       363\n",
      "\n",
      "FDR: 0.039415751759126816\n",
      "[[334  22]\n",
      " [  7   0]]\n",
      "channel: A\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.90      0.86      2818\n",
      "           1       0.01      0.00      0.00       556\n",
      "\n",
      "    accuracy                           0.75      3374\n",
      "   macro avg       0.41      0.45      0.43      3374\n",
      "weighted avg       0.69      0.75      0.72      3374\n",
      "\n",
      "FDR: 0.31316213686240546\n",
      "[[2540  278]\n",
      " [ 554    2]]\n",
      "channel: E\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.92      0.91      4882\n",
      "           1       0.13      0.09      0.11       604\n",
      "\n",
      "    accuracy                           0.83      5486\n",
      "   macro avg       0.51      0.51      0.51      5486\n",
      "weighted avg       0.81      0.83      0.82      5486\n",
      "\n",
      "FDR: 0.19293290105481908\n",
      "[[4494  388]\n",
      " [ 548   56]]\n",
      "channel: B\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.93      0.96       397\n",
      "           1       0.00      0.00      0.00         6\n",
      "\n",
      "    accuracy                           0.92       403\n",
      "   macro avg       0.49      0.47      0.48       403\n",
      "weighted avg       0.97      0.92      0.94       403\n",
      "\n",
      "FDR: 0.03056650716443643\n",
      "[[371  26]\n",
      " [  6   0]]\n"
     ]
    }
   ],
   "source": [
    "for channel in fitted_data:\n",
    "    isolation_forest_default(fitted_data[channel], channel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "baa41085-279e-46b1-b001-274dd234df28",
   "metadata": {},
   "outputs": [],
   "source": [
    "#LOF learns a reference density from X_train, new points are compared against training density\n",
    "def local_outlier_factor_manual(channel_data, channel):\n",
    "    print(\"channel:\", channel)\n",
    "    clf = LocalOutlierFactor(n_neighbors=20, novelty=True)\n",
    "    clf.fit(channel_data[\"train\"])\n",
    "    decision_scores = clf.decision_function(channel_data[\"test\"])\n",
    "    \n",
    "    thresholds = []\n",
    "    for score in decision_scores: \n",
    "        if score < 0:\n",
    "            thresholds.append(score)\n",
    "    \n",
    "    best_f1_score = 0\n",
    "    best_recall_score = 0\n",
    "    best_thresholds = []\n",
    "    best_threshold = 0\n",
    "\n",
    "    # for th in thresholds:\n",
    "    #     y_pred = predict(th, decision_scores)\n",
    "    #     f1 = f1_score(channel_data[\"label\"], y_pred)\n",
    "    #     if (best_f1_score <= f1):\n",
    "    #         best_f1_score = f1\n",
    "    #         best_threshold = th\n",
    "\n",
    "    for th in thresholds:\n",
    "        y_pred = predict(th, decision_scores)\n",
    "        recall = recall_score(channel_data[\"label\"], y_pred)\n",
    "        if (best_recall_score <= recall):\n",
    "            best_recall_score = recall\n",
    "            best_thresholds.append(th) \n",
    "    \n",
    "    for th in best_thresholds:\n",
    "        y_pred = predict(th, decision_scores)\n",
    "        f1 = f1_score(channel_data[\"label\"], y_pred)\n",
    "        if (best_f1_score <= f1):\n",
    "            best_f1_score = f1\n",
    "            best_threshold = th\n",
    "    \n",
    "    y_test = channel_data[\"label\"]\n",
    "    y_pred = predict(best_threshold, decision_scores)\n",
    "    print(\"best_threshold: \", best_threshold)\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    precision = precision_score(y_test, y_pred, average='weighted')\n",
    "    print(\"FDR:\", 1 - precision)\n",
    "    c_m = confusion_matrix(y_test, y_pred)\n",
    "    print(c_m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "1b03baf5-f289-4733-9415-955e066d63a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(threshold, decision_scores):\n",
    "    y_pred = []\n",
    "    for score in decision_scores: \n",
    "        if score < threshold: \n",
    "            y_pred.append(1)\n",
    "        else:\n",
    "            y_pred.append(0)\n",
    "    return np.array(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "c7c42bea-6020-47ad-adbb-85dcf6bb4ae4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "channel: T\n",
      "best_threshold:  -0.22083306\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.98      0.91      1103\n",
      "           1       0.26      0.04      0.06       189\n",
      "\n",
      "    accuracy                           0.84      1292\n",
      "   macro avg       0.56      0.51      0.49      1292\n",
      "weighted avg       0.77      0.84      0.79      1292\n",
      "\n",
      "FDR: 0.23118613786267572\n",
      "[[1083   20]\n",
      " [ 182    7]]\n",
      "channel: G\n",
      "best_threshold:  -0.016273856\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.74      0.85      2354\n",
      "           1       0.05      0.59      0.09        51\n",
      "\n",
      "    accuracy                           0.74      2405\n",
      "   macro avg       0.52      0.66      0.47      2405\n",
      "weighted avg       0.97      0.74      0.83      2405\n",
      "\n",
      "FDR: 0.03190646437706657\n",
      "[[1738  616]\n",
      " [  21   30]]\n",
      "channel: S\n",
      "best_threshold:  -0.23041058\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      1.00      0.98       342\n",
      "           1       0.92      0.48      0.63        25\n",
      "\n",
      "    accuracy                           0.96       367\n",
      "   macro avg       0.94      0.74      0.81       367\n",
      "weighted avg       0.96      0.96      0.96       367\n",
      "\n",
      "FDR: 0.039461577539442017\n",
      "[[341   1]\n",
      " [ 13  12]]\n",
      "channel: P\n",
      "best_threshold:  -0.015904784\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.96      0.92      1761\n",
      "           1       0.47      0.20      0.28       295\n",
      "\n",
      "    accuracy                           0.85      2056\n",
      "   macro avg       0.67      0.58      0.60      2056\n",
      "weighted avg       0.82      0.85      0.83      2056\n",
      "\n",
      "FDR: 0.18083941897611622\n",
      "[[1696   65]\n",
      " [ 237   58]]\n",
      "channel: D\n",
      "best_threshold:  -0.0010465384\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.92      0.84      3705\n",
      "           1       0.21      0.07      0.10      1084\n",
      "\n",
      "    accuracy                           0.73      4789\n",
      "   macro avg       0.49      0.50      0.47      4789\n",
      "weighted avg       0.64      0.73      0.67      4789\n",
      "\n",
      "FDR: 0.35539443646707614\n",
      "[[3424  281]\n",
      " [1010   74]]\n",
      "channel: F\n",
      "best_threshold:  -0.034662127\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.79      0.85      1118\n",
      "           1       0.23      0.43      0.30       163\n",
      "\n",
      "    accuracy                           0.75      1281\n",
      "   macro avg       0.57      0.61      0.57      1281\n",
      "weighted avg       0.82      0.75      0.78      1281\n",
      "\n",
      "FDR: 0.18065794936634527\n",
      "[[886 232]\n",
      " [ 93  70]]\n",
      "channel: R\n",
      "best_threshold:  -17520790000.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.05      0.10       356\n",
      "           1       0.02      1.00      0.04         7\n",
      "\n",
      "    accuracy                           0.07       363\n",
      "   macro avg       0.51      0.53      0.07       363\n",
      "weighted avg       0.98      0.07      0.10       363\n",
      "\n",
      "FDR: 0.01889248213358885\n",
      "[[ 18 338]\n",
      " [  0   7]]\n",
      "channel: A\n",
      "best_threshold:  -0.0038630962\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.69      0.77      2818\n",
      "           1       0.23      0.46      0.31       556\n",
      "\n",
      "    accuracy                           0.65      3374\n",
      "   macro avg       0.55      0.58      0.54      3374\n",
      "weighted avg       0.76      0.65      0.69      3374\n",
      "\n",
      "FDR: 0.23766599412468015\n",
      "[[1951  867]\n",
      " [ 298  258]]\n",
      "channel: E\n",
      "best_threshold:  -0.0064589977\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.78      0.85      4882\n",
      "           1       0.24      0.55      0.33       604\n",
      "\n",
      "    accuracy                           0.76      5486\n",
      "   macro avg       0.59      0.67      0.59      5486\n",
      "weighted avg       0.86      0.76      0.79      5486\n",
      "\n",
      "FDR: 0.142702427529945\n",
      "[[3814 1068]\n",
      " [ 270  334]]\n",
      "channel: B\n",
      "best_threshold:  -156910980000.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.63      0.77       397\n",
      "           1       0.04      1.00      0.08         6\n",
      "\n",
      "    accuracy                           0.64       403\n",
      "   macro avg       0.52      0.81      0.42       403\n",
      "weighted avg       0.99      0.64      0.76       403\n",
      "\n",
      "FDR: 0.014304481097649924\n",
      "[[250 147]\n",
      " [  0   6]]\n"
     ]
    }
   ],
   "source": [
    "for channel in fitted_data:\n",
    "    local_outlier_factor_manual(fitted_data[channel], channel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6df5f1a-9634-4f6c-8555-c8d94ccdbcb8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10",
   "language": "python",
   "name": "python-3.10"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
