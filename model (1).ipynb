{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e2cfce4d-82c7-43cf-a818-594b73f5d325",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import necessary packages\n",
    "from pathlib import Path\n",
    "import os\n",
    "import ast\n",
    "import shutil\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.metrics import classification_report, confusion_matrix, ConfusionMatrixDisplay, precision_score\n",
    "from sklearn.svm import OneClassSVM\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "from sktime.transformations.panel.rocket import (\n",
    "    MiniRocket,\n",
    "    MiniRocketMultivariate,\n",
    "    MiniRocketMultivariateVariable,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ecfa9908-f807-42be-b37c-be84a9b87ec1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(train) df:  D-12 (312, 25) index:  0\n",
      "(train) df:  T-2 (2855, 25) index:  1\n",
      "(train) df:  E-7 (2769, 25) index:  2\n",
      "(train) df:  S-1 (2818, 25) index:  3\n",
      "(train) df:  E-9 (2880, 25) index:  4\n",
      "(train) df:  G-1 (2820, 25) index:  5\n",
      "(train) df:  G-6 (2881, 25) index:  6\n",
      "(train) df:  D-7 (2583, 25) index:  7\n",
      "(train) df:  R-1 (2874, 25) index:  8\n",
      "(train) df:  D-9 (2583, 25) index:  9\n",
      "(train) df:  A-2 (2648, 25) index:  10\n",
      "(train) df:  A-5 (705, 25) index:  11\n",
      "(train) df:  P-7 (2853, 25) index:  12\n",
      "(train) df:  F-1 (2869, 25) index:  13\n",
      "(train) df:  E-11 (2880, 25) index:  14\n",
      "(train) df:  G-7 (2446, 25) index:  15\n",
      "(train) df:  E-8 (2880, 25) index:  16\n",
      "(train) df:  E-6 (2880, 25) index:  17\n",
      "(train) df:  D-13 (1490, 25) index:  18\n",
      "(train) df:  E-1 (2880, 25) index:  19\n",
      "(train) df:  T-3 (2876, 25) index:  20\n",
      "(train) df:  E-10 (2880, 25) index:  21\n",
      "(train) df:  A-4 (2690, 25) index:  22\n",
      "(train) df:  P-1 (2872, 25) index:  23\n",
      "(train) df:  A-3 (2736, 25) index:  24\n",
      "(train) df:  D-8 (2602, 25) index:  25\n",
      "(train) df:  D-6 (2594, 25) index:  26\n",
      "(train) df:  D-1 (2849, 25) index:  27\n",
      "(train) df:  A-9 (762, 25) index:  28\n",
      "(train) df:  F-3 (2880, 25) index:  29\n",
      "(train) df:  E-13 (2880, 25) index:  30\n",
      "(train) df:  P-2 (2821, 25) index:  31\n",
      "(train) df:  A-7 (2879, 25) index:  32\n",
      "(train) df:  D-2 (2880, 25) index:  33\n",
      "(train) df:  D-5 (2561, 25) index:  34\n",
      "(train) df:  G-3 (2624, 25) index:  35\n",
      "(train) df:  G-4 (2551, 25) index:  36\n",
      "(train) df:  B-1 (2435, 25) index:  37\n",
      "(train) df:  E-2 (2880, 25) index:  38\n",
      "(train) df:  E-5 (2880, 25) index:  39\n",
      "(train) df:  D-4 (2833, 25) index:  40\n",
      "(train) df:  D-3 (2880, 25) index:  41\n",
      "(train) df:  A-6 (682, 25) index:  42\n",
      "(train) df:  P-4 (2609, 25) index:  43\n",
      "(train) df:  P-3 (2855, 25) index:  44\n",
      "(train) df:  A-1 (2880, 25) index:  45\n",
      "(train) df:  E-12 (2880, 25) index:  46\n",
      "(train) df:  A-8 (762, 25) index:  47\n",
      "(train) df:  F-2 (2861, 25) index:  48\n",
      "(train) df:  E-4 (2880, 25) index:  49\n",
      "(train) df:  D-11 (2611, 25) index:  50\n",
      "(train) df:  E-3 (2880, 25) index:  51\n",
      "(train) df:  T-1 (2875, 25) index:  52\n",
      "(train) df:  G-2 (2478, 25) index:  53\n",
      "(test) df:  G-2 (7361, 25) index:  0\n",
      "(test) df:  T-1 (8612, 25) index:  1\n",
      "(test) df:  E-3 (8307, 25) index:  2\n",
      "(test) df:  E-4 (8354, 25) index:  3\n",
      "(test) df:  D-11 (7431, 25) index:  4\n",
      "(test) df:  A-1 (8640, 25) index:  5\n",
      "(test) df:  P-3 (8493, 25) index:  6\n",
      "(test) df:  E-12 (8512, 25) index:  7\n",
      "(test) df:  P-4 (7783, 25) index:  8\n",
      "(test) df:  A-6 (4453, 25) index:  9\n",
      "(test) df:  F-2 (8626, 25) index:  10\n",
      "(test) df:  A-8 (8375, 25) index:  11\n",
      "(test) df:  D-3 (8640, 25) index:  12\n",
      "(test) df:  D-4 (8473, 25) index:  13\n",
      "(test) df:  B-1 (8044, 25) index:  14\n",
      "(test) df:  E-5 (8294, 25) index:  15\n",
      "(test) df:  E-2 (8532, 25) index:  16\n",
      "(test) df:  G-4 (7632, 25) index:  17\n",
      "(test) df:  G-3 (7907, 25) index:  18\n",
      "(test) df:  D-5 (7628, 25) index:  19\n",
      "(test) df:  D-2 (8595, 25) index:  20\n",
      "(test) df:  F-3 (8376, 25) index:  21\n",
      "(test) df:  A-9 (8434, 25) index:  22\n",
      "(test) df:  E-13 (8640, 25) index:  23\n",
      "(test) df:  A-7 (8631, 25) index:  24\n",
      "(test) df:  P-2 (8209, 25) index:  25\n",
      "(test) df:  D-8 (7874, 25) index:  26\n",
      "(test) df:  D-1 (8509, 25) index:  27\n",
      "(test) df:  D-6 (7884, 25) index:  28\n",
      "(test) df:  A-3 (8205, 25) index:  29\n",
      "(test) df:  P-1 (8505, 25) index:  30\n",
      "(test) df:  E-10 (8505, 25) index:  31\n",
      "(test) df:  A-4 (8080, 25) index:  32\n",
      "(test) df:  E-8 (8532, 25) index:  33\n",
      "(test) df:  D-13 (7663, 25) index:  34\n",
      "(test) df:  T-3 (8579, 25) index:  35\n",
      "(test) df:  E-1 (8516, 25) index:  36\n",
      "(test) df:  E-6 (8300, 25) index:  37\n",
      "(test) df:  G-7 (8029, 25) index:  38\n",
      "(test) df:  E-11 (8514, 25) index:  39\n",
      "(test) df:  P-7 (8071, 25) index:  40\n",
      "(test) df:  A-5 (4693, 25) index:  41\n",
      "(test) df:  A-2 (7914, 25) index:  42\n",
      "(test) df:  F-1 (8584, 25) index:  43\n",
      "(test) df:  D-7 (7642, 25) index:  44\n",
      "(test) df:  R-1 (7244, 25) index:  45\n",
      "(test) df:  D-9 (7406, 25) index:  46\n",
      "(test) df:  G-6 (8640, 25) index:  47\n",
      "(test) df:  G-1 (8469, 25) index:  48\n",
      "(test) df:  E-7 (8310, 25) index:  49\n",
      "(test) df:  T-2 (8625, 25) index:  50\n",
      "(test) df:  S-1 (7331, 25) index:  51\n",
      "(test) df:  E-9 (8302, 25) index:  52\n",
      "(test) df:  D-12 (7918, 25) index:  53\n"
     ]
    }
   ],
   "source": [
    "#collection of dataset information for each telemetry data \n",
    "training_dfs = []\n",
    "test_dfs = []\n",
    "\n",
    "training_df = []\n",
    "test_df = []\n",
    "\n",
    "file_names = []\n",
    "\n",
    "label_df = pd.read_csv(\"labeled_anomalies.csv\")\n",
    "\n",
    "train_data_path = \"npy_train\" \n",
    "test_data_path = \"npy_test\" \n",
    "\n",
    "os.makedirs(\"raw_train\", exist_ok=True)\n",
    "os.makedirs(\"raw_test\", exist_ok=True)\n",
    "\n",
    "index = 0\n",
    "for root, _, files in os.walk(train_data_path):\n",
    "    for file in files:\n",
    "        example_path = os.path.join(root, file)\n",
    "        filename = Path(example_path).stem\n",
    "        \n",
    "        row_indices = label_df[label_df['chan_id'] == filename].index.tolist()\n",
    "        if not row_indices:\n",
    "            continue\n",
    "        spacecraft = label_df.loc[row_indices[0], 'spacecraft']\n",
    "        \n",
    "        if (spacecraft == \"SMAP\"): \n",
    "            data = np.load(example_path)\n",
    "            df = pd.DataFrame(data)\n",
    "            print(\"(train) df: \", filename, df.shape, \"index: \", index)\n",
    "            df.to_csv(f\"raw_train/{filename}.csv\", index=False)\n",
    "            training_dfs.append(df) \n",
    "            index += 1\n",
    "\n",
    "index = 0\n",
    "for root, _, files in os.walk(test_data_path):\n",
    "    for file in files:\n",
    "        example_path = os.path.join(root, file)\n",
    "        filename = Path(example_path).stem\n",
    "        \n",
    "        row_indices = label_df[label_df['chan_id'] == filename].index.tolist()\n",
    "        if not row_indices:\n",
    "            continue\n",
    "        spacecraft = label_df.loc[row_indices[0], 'spacecraft']\n",
    "        \n",
    "        if (spacecraft == \"SMAP\"): \n",
    "            data = np.load(example_path)\n",
    "            df = pd.DataFrame(data)\n",
    "            print(\"(test) df: \", filename, df.shape, \"index: \", index)\n",
    "            df.to_csv(f\"raw_test/{filename}.csv\", index=False)\n",
    "            test_dfs.append(df) \n",
    "            file_names.append(filename)\n",
    "            \n",
    "            index += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d49f058b-3a33-4b1a-a147-81c717e1645e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data():\n",
    "    training_dfs = {}\n",
    "    test_dfs = {}\n",
    "    file_names = {\"train\": {}, \"test\": {}}\n",
    "    label_df = pd.read_csv(\"labeled_anomalies.csv\")\n",
    "    train_data_path = \"raw_train\" \n",
    "    test_data_path = \"raw_test\" \n",
    "    \n",
    "    for root, _, files in os.walk(train_data_path):\n",
    "        for file in files:\n",
    "            example_path = os.path.join(root, file)\n",
    "            filename = Path(example_path).stem\n",
    "            df = pd.read_csv(example_path)\n",
    "            channel = filename[0]            \n",
    "            if (training_dfs.get(channel) == None):\n",
    "                training_dfs[channel] = []\n",
    "                file_names[\"train\"][channel] = []\n",
    "                training_dfs[channel].append(df)\n",
    "                file_names[\"train\"][channel].append(filename)\n",
    "            else:\n",
    "                training_dfs[channel].append(df)\n",
    "                file_names[\"train\"][channel].append(filename)\n",
    "    \n",
    "    for root, _, files in os.walk(test_data_path):\n",
    "        for file in files:\n",
    "            example_path = os.path.join(root, file)\n",
    "            filename = Path(example_path).stem\n",
    "            df = pd.read_csv(example_path)\n",
    "            channel = filename[0]\n",
    "            if (test_dfs.get(channel) == None):\n",
    "                test_dfs[channel] = []\n",
    "                file_names[\"test\"][channel] = []\n",
    "                test_dfs[channel].append(df)\n",
    "                file_names[\"test\"][channel].append(filename)\n",
    "            else:\n",
    "                test_dfs[channel].append(df)\n",
    "                file_names[\"test\"][channel].append(filename)\n",
    "\n",
    "    return (training_dfs, test_dfs, label_df, file_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b7af7343-fd52-45db-9b3a-0cf2358da275",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_windows(training_dfs, test_dfs, window_size, window_overlap, label_df, file_names):\n",
    "    training_data = {}\n",
    "    test_data = {}\n",
    "    label_data = {}\n",
    "    \n",
    "    for channel in training_dfs.keys():\n",
    "        training_data[channel] = []\n",
    "        for df in training_dfs[channel]: \n",
    "            for i in range(0, len(df), window_overlap):\n",
    "                window = []\n",
    "                if i + window_size > len(df): \n",
    "                    window = df.iloc[-window_size:].to_numpy().tolist()\n",
    "                else: \n",
    "                    window = df.iloc[i:i + window_size].to_numpy().tolist()\n",
    "                np_window = np.array(window)\n",
    "                transposed_window = np_window.T\n",
    "                normal_window = transposed_window.tolist() \n",
    "                training_data[channel].append(normal_window)\n",
    "                \n",
    "    for channel in test_dfs.keys():\n",
    "        test_data[channel] = []\n",
    "        label_data[channel] = []\n",
    "        for i in range(len(test_dfs[channel])):\n",
    "            df = test_dfs[channel][i]\n",
    "            for j in range(0, len(df), window_overlap):\n",
    "                window = []\n",
    "                if j + window_size > len(df): \n",
    "                    window = df.iloc[-window_size:].to_numpy().tolist()\n",
    "                else: \n",
    "                    window = df.iloc[j:j + window_size].to_numpy().tolist()\n",
    "                row_indices = label_df[label_df[\"chan_id\"] == file_names[\"test\"][channel][i]].index.tolist()\n",
    "                \n",
    "                if not row_indices:\n",
    "                    continue\n",
    "\n",
    "                anomaly_sequence = label_df.loc[row_indices[0], 'anomaly_sequences']\n",
    "                anomaly_sequence = ast.literal_eval(anomaly_sequence)\n",
    "                labeled = False\n",
    "                for anomalies in anomaly_sequence:\n",
    "                    if (not(anomalies[1] <= j or anomalies[0] >= j + window_size)) and labeled == False:\n",
    "                        label_data[channel].append(1)\n",
    "                        labeled = True\n",
    "                if labeled == False:\n",
    "                    label_data[channel].append(0)\n",
    "                np_window = np.array(window)\n",
    "                transposed_window = np_window.T\n",
    "                normal_window = transposed_window.tolist() \n",
    "                test_data[channel].append(normal_window)\n",
    "                \n",
    "    return (training_data, test_data, label_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1d0c50c2-a610-488e-8e78-a346d393de6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train (842, 25, 60)\n",
      "train (703, 25, 60)\n",
      "train (432, 25, 60)\n",
      "train (1445, 25, 60)\n",
      "train (144, 25, 60)\n",
      "train (793, 25, 60)\n",
      "train (431, 25, 60)\n",
      "train (1867, 25, 60)\n",
      "train (141, 25, 60)\n",
      "train (122, 25, 60)\n",
      "test (5486, 25, 60)\n",
      "test (1292, 25, 60)\n",
      "test (2405, 25, 60)\n",
      "test (4789, 25, 60)\n",
      "test (3374, 25, 60)\n",
      "test (1281, 25, 60)\n",
      "test (2056, 25, 60)\n",
      "test (403, 25, 60)\n",
      "test (363, 25, 60)\n",
      "test (367, 25, 60)\n",
      "label (5486,)\n",
      "label (1292,)\n",
      "label (2405,)\n",
      "label (4789,)\n",
      "label (3374,)\n",
      "label (1281,)\n",
      "label (2056,)\n",
      "label (403,)\n",
      "label (363,)\n",
      "label (367,)\n"
     ]
    }
   ],
   "source": [
    "window_size = 60 \n",
    "window_overlap = 20\n",
    "training_dfs, test_dfs, label_df, file_names = get_data()\n",
    "\n",
    "X_train_collection, X_test_collection, y_test_collection = create_windows(training_dfs, test_dfs, window_size, window_overlap, label_df, file_names)\n",
    "\n",
    "os.makedirs(\"training_data\", exist_ok=True)\n",
    "os.makedirs(\"testing_data\", exist_ok=True)\n",
    "os.makedirs(\"label_data\", exist_ok=True)\n",
    "\n",
    "for channel in X_train_collection: \n",
    "    X_train = np.array(X_train_collection[channel])\n",
    "    print(\"train\" ,X_train.shape)\n",
    "    # train_df = pd.DataFrame(X_train)\n",
    "    # train_df.to_csv(f\"training_data{channel}.csv\", index=False)\n",
    "    \n",
    "for channel in X_test_collection: \n",
    "    X_test = np.array(X_test_collection[channel])\n",
    "    # test_df = pd.DataFrame(X_test)\n",
    "    # test_df.to_csv(f\"testing_data/{channel}.csv\", index=False)\n",
    "    print(\"test\" ,X_test.shape)\n",
    "for channel in y_test_collection: \n",
    "    y_test =  np.array(y_test_collection[channel])\n",
    "    # true_label_df = pd.DataFrame(y_test)\n",
    "    # true_label_df.to_csv(f\"label_data/{channel}.csv\", index=False)\n",
    "    print(\"label\" ,y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8916e30a-ea28-467c-a281-986881bd9da8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "channel:  A\n",
      "(transformed train):  (842, 9996)\n",
      "(transformed test):  (3374, 9996)\n",
      "channel:  P\n",
      "(transformed train):  (703, 9996)\n",
      "(transformed test):  (2056, 9996)\n",
      "channel:  F\n",
      "(transformed train):  (432, 9996)\n",
      "(transformed test):  (1281, 9996)\n",
      "channel:  D\n",
      "(transformed train):  (1445, 9996)\n",
      "(transformed test):  (4789, 9996)\n",
      "channel:  R\n",
      "(transformed train):  (144, 9996)\n",
      "(transformed test):  (363, 9996)\n",
      "channel:  G\n",
      "(transformed train):  (793, 9996)\n",
      "(transformed test):  (2405, 9996)\n",
      "channel:  T\n",
      "(transformed train):  (431, 9996)\n",
      "(transformed test):  (1292, 9996)\n",
      "channel:  E\n",
      "(transformed train):  (1867, 9996)\n",
      "(transformed test):  (5486, 9996)\n",
      "channel:  S\n",
      "(transformed train):  (141, 9996)\n",
      "(transformed test):  (367, 9996)\n",
      "channel:  B\n",
      "(transformed train):  (122, 9996)\n",
      "(transformed test):  (403, 9996)\n",
      "channel:  E\n",
      "label (5486,)\n",
      "channel:  T\n",
      "label (1292,)\n",
      "channel:  G\n",
      "label (2405,)\n",
      "channel:  D\n",
      "label (4789,)\n",
      "channel:  A\n",
      "label (3374,)\n",
      "channel:  F\n",
      "label (1281,)\n",
      "channel:  P\n",
      "label (2056,)\n",
      "channel:  B\n",
      "label (403,)\n",
      "channel:  R\n",
      "label (363,)\n",
      "channel:  S\n",
      "label (367,)\n"
     ]
    }
   ],
   "source": [
    "X_transform_train_collection = {}\n",
    "X_transform_test_collection = {}\n",
    "y_true_label_collection = {}\n",
    "\n",
    "for channel in X_train_collection: \n",
    "    minirocket = MiniRocketMultivariate(n_jobs = 2, random_state = 42) \n",
    "    X_train = np.array(X_train_collection[channel])\n",
    "    if (X_test_collection.get(channel) is None or y_test_collection.get(channel) is None):  \n",
    "        continue\n",
    "    X_test = np.array(X_test_collection[channel])\n",
    "    minirocket.fit(X_train)\n",
    "    X_transform_train = minirocket.transform(X_train)\n",
    "    X_transform_test = minirocket.transform(X_test)\n",
    "    X_transform_train_collection[channel] = X_transform_train\n",
    "    X_transform_test_collection[channel] = X_transform_test\n",
    "    print(\"channel: \", channel)\n",
    "    print(\"(transformed train): \" ,X_transform_train.shape)\n",
    "    print(\"(transformed test): \" ,X_transform_test.shape)\n",
    "\n",
    "for channel in y_test_collection: \n",
    "    y_test =  np.array(y_test_collection[channel])\n",
    "    y_true_label_collection[channel] = y_test\n",
    "    print(\"channel: \", channel)\n",
    "    print(\"label\" ,y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e38d02f6-6973-4871-b93e-2e7fcba2727b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_transform_train_df = pd.DataFrame(X_transform_train)\n",
    "X_transform_test_df = pd.DataFrame(X_transform_test)\n",
    "X_transform_train_df.to_csv(\"rocket_train.csv\", index=False)\n",
    "X_transform_test_df.to_csv(\"rocket_test.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c299bcd5-4795-4e06-a8de-cf0c38e70a35",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()\n",
    "X_fit_train = scaler.fit_transform(X_transform_train)\n",
    "X_fit_test = scaler.transform(X_transform_test)\n",
    "\n",
    "clf = OneClassSVM(gamma='auto').fit(X_fit_train)\n",
    "y_pred = clf.predict(X_fit_test)\n",
    "\n",
    "# print(\"params: \", grid_search.best_params_)\n",
    "# print(\"score: \", best_svc_model.score(fit_X_test, y_test))\n",
    "print(classification_report(y_test, y_pred))\n",
    "precision = precision_score(y_test, y_pred, average='weighted')\n",
    "print(\"FDR:\", 1 - precision)\n",
    "c_m = confusion_matrix(y_test, y_pred)\n",
    "print(c_m)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=c_m)\n",
    "disp.plot(cmap='Blues')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d08861dd-682d-4d8a-b578-231ea5f35dc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "        'n_estimators': [100, 200, 300, 400],\n",
    "        'C': [1, 10, 100, 1000],\n",
    "        'gamma': [0.0001, 0.001, 0.01, 0.1]\n",
    "        }\n",
    "\n",
    "clf = IsolationForest(random_state=0).fit(X_transform_train)\n",
    "y_pred = clf.predict(X_transform_test)\n",
    "\n",
    "# print(\"params: \", grid_search.best_params_)\n",
    "# print(\"score: \", best_svc_model.score(fit_X_test, y_test))\n",
    "print(classification_report(y_test, y_pred))\n",
    "precision = precision_score(y_test, y_pred, average='weighted')\n",
    "print(\"FDR:\", 1 - precision)\n",
    "c_m = confusion_matrix(y_test, y_pred)\n",
    "print(c_m)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=c_m)\n",
    "disp.plot(cmap='Blues')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "baa41085-279e-46b1-b001-274dd234df28",
   "metadata": {},
   "outputs": [],
   "source": [
    "#implement KNN\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "382a662e-ebbd-4d17-a69a-3ce18e20f912",
   "metadata": {},
   "outputs": [],
   "source": [
    "#implement GridSearch \n",
    "\n",
    "# svc = SVC(class_weight='balanced', random_state=42)\n",
    "# param_grid = {\n",
    "#         'kernel': ['poly'],\n",
    "#         'degree': [2, 3, 4],\n",
    "#         'C': [1, 10, 100, 1000],\n",
    "#         'gamma': [0.0001, 0.001, 0.01, 0.1]\n",
    "#         }\n",
    "# grid_search = GridSearchCV(estimator=svc, param_grid=param_grid, scoring='f1_weighted', cv=10, n_jobs=-1)\n",
    "# grid_search.fit(fit_X_train, y_train)\n",
    "\n",
    "# best_svc_model = grid_search.best_estimator_\n",
    "# test_accuracy = best_svc_model.score(fit_X_test, y_test)\n",
    "# y_pred = best_svc_model.predict(fit_X_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa9f74c9-85c8-4701-b418-3d1378766f68",
   "metadata": {},
   "outputs": [],
   "source": [
    "#implement grid search for unsupervised learning\n",
    "#flattening feature engineering \n",
    "#rocket multithreading \n",
    "#window prediction brainstorm"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10",
   "language": "python",
   "name": "python-3.10"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
