{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e2cfce4d-82c7-43cf-a818-594b73f5d325",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import necessary packages\n",
    "from pathlib import Path\n",
    "import os\n",
    "import ast\n",
    "import shutil\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.metrics import classification_report, confusion_matrix, ConfusionMatrixDisplay, precision_score, recall_score, f1_score\n",
    "from sklearn.svm import OneClassSVM\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "from sklearn.neighbors import LocalOutlierFactor\n",
    "from sktime.transformations.panel.rocket import (\n",
    "    MiniRocket,\n",
    "    MiniRocketMultivariate,\n",
    "    MiniRocketMultivariateVariable,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ecfa9908-f807-42be-b37c-be84a9b87ec1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#collection of dataset information for each telemetry data \n",
    "training_dfs = []\n",
    "test_dfs = []\n",
    "\n",
    "training_df = []\n",
    "test_df = []\n",
    "\n",
    "file_names = []\n",
    "\n",
    "label_df = pd.read_csv(\"labeled_anomalies.csv\")\n",
    "\n",
    "train_data_path = \"npy_train\" \n",
    "test_data_path = \"npy_test\" \n",
    "\n",
    "os.makedirs(\"raw_train\", exist_ok=True)\n",
    "os.makedirs(\"raw_test\", exist_ok=True)\n",
    "\n",
    "index = 0\n",
    "for root, _, files in os.walk(train_data_path):\n",
    "    for file in files:\n",
    "        example_path = os.path.join(root, file)\n",
    "        filename = Path(example_path).stem\n",
    "        \n",
    "        row_indices = label_df[label_df['chan_id'] == filename].index.tolist()\n",
    "        if not row_indices:\n",
    "            continue\n",
    "        spacecraft = label_df.loc[row_indices[0], 'spacecraft']\n",
    "        \n",
    "        if (spacecraft == \"SMAP\"): \n",
    "            data = np.load(example_path)\n",
    "            df = pd.DataFrame(data)\n",
    "            print(\"(train) df: \", filename, df.shape, \"index: \", index)\n",
    "            df.to_csv(f\"raw_train/{filename}.csv\", index=False)\n",
    "            training_dfs.append(df) \n",
    "            index += 1\n",
    "\n",
    "index = 0\n",
    "for root, _, files in os.walk(test_data_path):\n",
    "    for file in files:\n",
    "        example_path = os.path.join(root, file)\n",
    "        filename = Path(example_path).stem\n",
    "        \n",
    "        row_indices = label_df[label_df['chan_id'] == filename].index.tolist()\n",
    "        if not row_indices:\n",
    "            continue\n",
    "        spacecraft = label_df.loc[row_indices[0], 'spacecraft']\n",
    "        \n",
    "        if (spacecraft == \"SMAP\"): \n",
    "            data = np.load(example_path)\n",
    "            df = pd.DataFrame(data)\n",
    "            print(\"(test) df: \", filename, df.shape, \"index: \", index)\n",
    "            test_dfs.append(df) \n",
    "            file_names.append(filename)\n",
    "            \n",
    "            index += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d49f058b-3a33-4b1a-a147-81c717e1645e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data():\n",
    "    training_dfs = {}\n",
    "    test_dfs = {}\n",
    "    file_names = {\"train\": {}, \"test\": {}}\n",
    "    label_df = pd.read_csv(\"labeled_anomalies.csv\")\n",
    "    train_data_path = \"raw_train\" \n",
    "    test_data_path = \"raw_test\" \n",
    "    \n",
    "    for root, _, files in os.walk(train_data_path):\n",
    "        for file in files:\n",
    "            example_path = os.path.join(root, file)\n",
    "            filename = Path(example_path).stem\n",
    "            df = pd.read_csv(example_path)\n",
    "            channel = filename[0]            \n",
    "            if (training_dfs.get(channel) == None):\n",
    "                training_dfs[channel] = []\n",
    "                file_names[\"train\"][channel] = []\n",
    "                training_dfs[channel].append(df)\n",
    "                file_names[\"train\"][channel].append(filename)\n",
    "            else:\n",
    "                training_dfs[channel].append(df)\n",
    "                file_names[\"train\"][channel].append(filename)\n",
    "    \n",
    "    for root, _, files in os.walk(test_data_path):\n",
    "        for file in files:\n",
    "            example_path = os.path.join(root, file)\n",
    "            filename = Path(example_path).stem\n",
    "            df = pd.read_csv(example_path)\n",
    "            channel = filename[0]\n",
    "            if (test_dfs.get(channel) == None):\n",
    "                test_dfs[channel] = []\n",
    "                file_names[\"test\"][channel] = []\n",
    "                test_dfs[channel].append(df)\n",
    "                file_names[\"test\"][channel].append(filename)\n",
    "            else:\n",
    "                test_dfs[channel].append(df)\n",
    "                file_names[\"test\"][channel].append(filename)\n",
    "\n",
    "    return (training_dfs, test_dfs, label_df, file_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b7af7343-fd52-45db-9b3a-0cf2358da275",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_windows(training_dfs, test_dfs, window_size, window_overlap, label_df, file_names):\n",
    "    training_data = {}\n",
    "    test_data = {}\n",
    "    label_data = {}\n",
    "    \n",
    "    for channel in training_dfs.keys():\n",
    "        training_data[channel] = []\n",
    "        for df in training_dfs[channel]: \n",
    "            for i in range(0, len(df), window_overlap):\n",
    "                window = []\n",
    "                if i + window_size > len(df): \n",
    "                    window = df.iloc[-window_size:].to_numpy().tolist()\n",
    "                else: \n",
    "                    window = df.iloc[i:i + window_size].to_numpy().tolist()\n",
    "                np_window = np.array(window)\n",
    "                transposed_window = np_window.T\n",
    "                normal_window = transposed_window.tolist() \n",
    "                training_data[channel].append(normal_window)\n",
    "                \n",
    "    for channel in test_dfs.keys():\n",
    "        test_data[channel] = []\n",
    "        label_data[channel] = []\n",
    "        for i in range(len(test_dfs[channel])):\n",
    "            df = test_dfs[channel][i]\n",
    "            for j in range(0, len(df), window_overlap):\n",
    "                window = []\n",
    "                if j + window_size > len(df): \n",
    "                    window = df.iloc[-window_size:].to_numpy().tolist()\n",
    "                else: \n",
    "                    window = df.iloc[j:j + window_size].to_numpy().tolist()\n",
    "                row_indices = label_df[label_df[\"chan_id\"] == file_names[\"test\"][channel][i]].index.tolist()\n",
    "                \n",
    "                if not row_indices:\n",
    "                    continue\n",
    "\n",
    "                anomaly_sequence = label_df.loc[row_indices[0], 'anomaly_sequences']\n",
    "                anomaly_sequence = ast.literal_eval(anomaly_sequence)\n",
    "                labeled = False\n",
    "                for anomalies in anomaly_sequence:\n",
    "                    if (not(anomalies[1] <= j or anomalies[0] >= j + window_size)) and labeled == False:\n",
    "                        label_data[channel].append(1)\n",
    "                        labeled = True\n",
    "                if labeled == False:\n",
    "                    label_data[channel].append(0)\n",
    "                np_window = np.array(window)\n",
    "                transposed_window = np_window.T\n",
    "                normal_window = transposed_window.tolist() \n",
    "                test_data[channel].append(normal_window)\n",
    "                \n",
    "    return (training_data, test_data, label_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1d0c50c2-a610-488e-8e78-a346d393de6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train:  A shape:  (842, 25, 60)\n",
      "train:  P shape:  (703, 25, 60)\n",
      "train:  F shape:  (432, 25, 60)\n",
      "train:  D shape:  (1445, 25, 60)\n",
      "train:  R shape:  (144, 25, 60)\n",
      "train:  G shape:  (793, 25, 60)\n",
      "train:  T shape:  (431, 25, 60)\n",
      "train:  E shape:  (1867, 25, 60)\n",
      "train:  S shape:  (141, 25, 60)\n",
      "train:  B shape:  (122, 25, 60)\n",
      "test:  E shape:  (5486, 25, 60)\n",
      "test:  T shape:  (1292, 25, 60)\n",
      "test:  G shape:  (2405, 25, 60)\n",
      "test:  D shape:  (4789, 25, 60)\n",
      "test:  A shape:  (3374, 25, 60)\n",
      "test:  F shape:  (1281, 25, 60)\n",
      "test:  P shape:  (2056, 25, 60)\n",
      "test:  B shape:  (403, 25, 60)\n",
      "test:  R shape:  (363, 25, 60)\n",
      "test:  S shape:  (367, 25, 60)\n",
      "label:  E shape:  (5486,)\n",
      "label:  T shape:  (1292,)\n",
      "label:  G shape:  (2405,)\n",
      "label:  D shape:  (4789,)\n",
      "label:  A shape:  (3374,)\n",
      "label:  F shape:  (1281,)\n",
      "label:  P shape:  (2056,)\n",
      "label:  B shape:  (403,)\n",
      "label:  R shape:  (363,)\n",
      "label:  S shape:  (367,)\n"
     ]
    }
   ],
   "source": [
    "window_size = 60 \n",
    "window_overlap = 20\n",
    "training_dfs, test_dfs, label_df, file_names = get_data()\n",
    "\n",
    "X_train_collection, X_test_collection, y_test_collection = create_windows(training_dfs, test_dfs, window_size, window_overlap, label_df, file_names)\n",
    "\n",
    "data = {}\n",
    "os.makedirs(\"data\", exist_ok=True)\n",
    "\n",
    "for channel in X_train_collection:\n",
    "    if data.get(channel) is None:\n",
    "        data[channel] = {}\n",
    "    if data.get(channel).get(\"train\") is None:\n",
    "        X_train = np.array(X_train_collection[channel])\n",
    "        path = f\"data/{channel}/train\"\n",
    "        os.makedirs(path, exist_ok=True)\n",
    "        np.save(path + f\"/{channel}.npy\", X_train)\n",
    "        data[channel][\"train\"] = path + f\"/{channel}.npy\"\n",
    "        print(\"train: \", channel, \"shape: \", X_train.shape)\n",
    "    else:\n",
    "        print(\"Error: duplicate training data sets\")\n",
    "   \n",
    "    \n",
    "for channel in X_test_collection: \n",
    "    if data.get(channel) is None:\n",
    "        continue\n",
    "    if data.get(channel).get(\"test\") is None:\n",
    "        X_test = np.array(X_test_collection[channel])\n",
    "        path = f\"data/{channel}/test\"\n",
    "        os.makedirs(path, exist_ok=True)\n",
    "        np.save(path + f\"/{channel}.npy\", X_test)\n",
    "        data[channel][\"test\"] = path + f\"/{channel}.npy\"\n",
    "        print(\"test: \", channel, \"shape: \", X_test.shape)\n",
    "    else:\n",
    "        print(\"Error: duplicate testing data sets\")\n",
    "   \n",
    "  \n",
    "for channel in y_test_collection:\n",
    "    if data.get(channel) is None:\n",
    "        continue\n",
    "    if data.get(channel).get(\"label\") is None:\n",
    "        y_test = np.array(y_test_collection[channel])\n",
    "        path = f\"data/{channel}/label\"\n",
    "        os.makedirs(path, exist_ok=True)\n",
    "        np.save(path + f\"/{channel}.npy\", y_test)\n",
    "        data[channel][\"label\"] = path + f\"/{channel}.npy\"\n",
    "        print(\"label: \", channel, \"shape: \", y_test.shape)\n",
    "    else:\n",
    "        print(\"Error: duplicate label data sets\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b62abdbd-26c4-4901-b050-32642e436af7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['T', 'G', 'S', 'P', 'D', 'F', 'R', 'A', 'E', 'B']\n"
     ]
    }
   ],
   "source": [
    "channel_names = []\n",
    "\n",
    "for channel in os.listdir(\"data\"):\n",
    "    if os.path.isdir(os.path.join(\"data\", channel)):\n",
    "        channel_names.append(channel)\n",
    "print(channel_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5c17dc62-a4ae-410f-a25e-1cf83cccd79e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train:  T shape:  (431, 25, 60)\n",
      "test:  T shape:  (1292, 25, 60)\n",
      "label:  T shape:  (1292,)\n",
      "train:  G shape:  (793, 25, 60)\n",
      "test:  G shape:  (2405, 25, 60)\n",
      "label:  G shape:  (2405,)\n",
      "train:  S shape:  (141, 25, 60)\n",
      "test:  S shape:  (367, 25, 60)\n",
      "label:  S shape:  (367,)\n",
      "train:  P shape:  (703, 25, 60)\n",
      "test:  P shape:  (2056, 25, 60)\n",
      "label:  P shape:  (2056,)\n",
      "train:  D shape:  (1445, 25, 60)\n",
      "test:  D shape:  (4789, 25, 60)\n",
      "label:  D shape:  (4789,)\n",
      "train:  F shape:  (432, 25, 60)\n",
      "test:  F shape:  (1281, 25, 60)\n",
      "label:  F shape:  (1281,)\n",
      "train:  R shape:  (144, 25, 60)\n",
      "test:  R shape:  (363, 25, 60)\n",
      "label:  R shape:  (363,)\n",
      "train:  A shape:  (842, 25, 60)\n",
      "test:  A shape:  (3374, 25, 60)\n",
      "label:  A shape:  (3374,)\n",
      "train:  E shape:  (1867, 25, 60)\n",
      "test:  E shape:  (5486, 25, 60)\n",
      "label:  E shape:  (5486,)\n",
      "train:  B shape:  (122, 25, 60)\n",
      "test:  B shape:  (403, 25, 60)\n",
      "label:  B shape:  (403,)\n"
     ]
    }
   ],
   "source": [
    "raw_data= {}\n",
    "for channel in channel_names:\n",
    "    raw_data[channel] = {}\n",
    "    training_data_path = f\"data/{channel}/train/{channel}.npy\"\n",
    "    testing_data_path = f\"data/{channel}/test/{channel}.npy\"\n",
    "    label_data_path = f\"data/{channel}/label/{channel}.npy\"\n",
    "    \n",
    "    X_train = np.load(training_data_path)\n",
    "    X_test = np.load(testing_data_path)\n",
    "    y_test = np.load(label_data_path)\n",
    "\n",
    "    raw_data[channel][\"train\"] = X_train\n",
    "    print(\"train: \", channel, \"shape: \", X_train.shape)\n",
    "    raw_data[channel][\"test\"] = X_test\n",
    "    print(\"test: \", channel, \"shape: \", X_test.shape)\n",
    "    raw_data[channel][\"label\"] = y_test\n",
    "    print(\"label: \", channel, \"shape: \", y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "26df1794-f418-4731-8425-ee5aae3be8bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/DAVIDSON/haotaki/.local/lib/python3.10/site-packages/numba/np/ufunc/parallel.py:373: NumbaWarning: \u001b[1mThe TBB threading layer requires TBB version 2021 update 6 or later i.e., TBB_INTERFACE_VERSION >= 12060. Found TBB_INTERFACE_VERSION = 12050. The TBB threading layer is disabled.\u001b[0m\n",
      "  warnings.warn(problem)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train:  T shape:  (431, 9996)\n",
      "test:  T shape:  (1292, 9996)\n",
      "label:  T shape:  (1292,)\n",
      "train:  G shape:  (793, 9996)\n",
      "test:  G shape:  (2405, 9996)\n",
      "label:  G shape:  (2405,)\n",
      "train:  S shape:  (141, 9996)\n",
      "test:  S shape:  (367, 9996)\n",
      "label:  S shape:  (367,)\n",
      "train:  P shape:  (703, 9996)\n",
      "test:  P shape:  (2056, 9996)\n",
      "label:  P shape:  (2056,)\n",
      "train:  D shape:  (1445, 9996)\n",
      "test:  D shape:  (4789, 9996)\n",
      "label:  D shape:  (4789,)\n",
      "train:  F shape:  (432, 9996)\n",
      "test:  F shape:  (1281, 9996)\n",
      "label:  F shape:  (1281,)\n",
      "train:  R shape:  (144, 9996)\n",
      "test:  R shape:  (363, 9996)\n",
      "label:  R shape:  (363,)\n",
      "train:  A shape:  (842, 9996)\n",
      "test:  A shape:  (3374, 9996)\n",
      "label:  A shape:  (3374,)\n",
      "train:  E shape:  (1867, 9996)\n",
      "test:  E shape:  (5486, 9996)\n",
      "label:  E shape:  (5486,)\n",
      "train:  B shape:  (122, 9996)\n",
      "test:  B shape:  (403, 9996)\n",
      "label:  B shape:  (403,)\n",
      "stoe:  T\n",
      "stoe:  G\n",
      "stoe:  S\n",
      "stoe:  P\n",
      "stoe:  D\n",
      "stoe:  F\n",
      "stoe:  R\n",
      "stoe:  A\n",
      "stoe:  E\n",
      "stoe:  B\n"
     ]
    }
   ],
   "source": [
    "transformed_data= {}\n",
    "os.makedirs(\"transformed_data\", exist_ok=True)\n",
    "\n",
    "for channel in channel_names:\n",
    "    transformed_data[channel] = {}\n",
    "    training_data_path = f\"data/{channel}/train/{channel}.npy\"\n",
    "    testing_data_path = f\"data/{channel}/test/{channel}.npy\"\n",
    "    label_data_path = f\"data/{channel}/label/{channel}.npy\"\n",
    "    \n",
    "    X_train = np.load(training_data_path)\n",
    "    X_test = np.load(testing_data_path)\n",
    "    y_test = np.load(label_data_path)\n",
    "\n",
    "    minirocket = MiniRocketMultivariate(num_kernels=10000, n_jobs = 2, random_state = 42) \n",
    "    minirocket.fit(X_train)\n",
    "    X_transform_train = minirocket.transform(X_train)\n",
    "    X_transform_test = minirocket.transform(X_test)\n",
    "\n",
    "    transformed_data[channel][\"train\"] = X_transform_train\n",
    "    print(\"train: \", channel, \"shape: \", X_transform_train.shape)\n",
    "    transformed_data[channel][\"test\"] = X_transform_test\n",
    "    print(\"test: \", channel, \"shape: \", X_transform_test.shape)\n",
    "    transformed_data[channel][\"label\"] = y_test\n",
    "    print(\"label: \", channel, \"shape: \", y_test.shape)\n",
    "\n",
    "for channel in transformed_data: \n",
    "    print(\"store: \", channel)\n",
    "    X_transform_train = transformed_data[channel][\"train\"]\n",
    "    X_transform_test = transformed_data[channel][\"test\"]\n",
    "    y_test = transformed_data[channel][\"label\"]\n",
    "\n",
    "    train_df = pd.DataFrame(X_transform_train)\n",
    "    test_df = pd.DataFrame(X_transform_test)\n",
    "    label_df = pd.DataFrame(y_test)\n",
    "\n",
    "    training_data_path = f\"transformed_data/{channel}/train\"\n",
    "    testing_data_path = f\"transformed_data/{channel}/test\"\n",
    "    label_data_path = f\"transformed_data/{channel}/label\"\n",
    "    \n",
    "    os.makedirs(training_data_path, exist_ok=True)\n",
    "    os.makedirs(testing_data_path, exist_ok=True)\n",
    "    os.makedirs(label_data_path, exist_ok=True)\n",
    "\n",
    "    train_df.to_csv(training_data_path + f\"/{channel}.csv\", index=False)\n",
    "    test_df.to_csv(testing_data_path + f\"/{channel}.csv\", index=False)\n",
    "    label_df.to_csv(label_data_path + f\"/{channel}.csv\", index=False)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ce77693b-1d71-449e-b769-a9cf8ca798d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train:  T shape:  (431, 9996)\n",
      "test:  T shape:  (1292, 9996)\n",
      "label:  T shape:  (1292, 1)\n",
      "train:  G shape:  (793, 9996)\n",
      "test:  G shape:  (2405, 9996)\n",
      "label:  G shape:  (2405, 1)\n",
      "train:  S shape:  (141, 9996)\n",
      "test:  S shape:  (367, 9996)\n",
      "label:  S shape:  (367, 1)\n",
      "train:  P shape:  (703, 9996)\n",
      "test:  P shape:  (2056, 9996)\n",
      "label:  P shape:  (2056, 1)\n",
      "train:  D shape:  (1445, 9996)\n",
      "test:  D shape:  (4789, 9996)\n",
      "label:  D shape:  (4789, 1)\n",
      "train:  F shape:  (432, 9996)\n",
      "test:  F shape:  (1281, 9996)\n",
      "label:  F shape:  (1281, 1)\n",
      "train:  R shape:  (144, 9996)\n",
      "test:  R shape:  (363, 9996)\n",
      "label:  R shape:  (363, 1)\n",
      "train:  A shape:  (842, 9996)\n",
      "test:  A shape:  (3374, 9996)\n",
      "label:  A shape:  (3374, 1)\n",
      "train:  E shape:  (1867, 9996)\n",
      "test:  E shape:  (5486, 9996)\n",
      "label:  E shape:  (5486, 1)\n",
      "train:  B shape:  (122, 9996)\n",
      "test:  B shape:  (403, 9996)\n",
      "label:  B shape:  (403, 1)\n"
     ]
    }
   ],
   "source": [
    "min_max_fitted_data = {}\n",
    "\n",
    "for channel in channel_names: \n",
    "    min_max_fitted_data[channel] = {}\n",
    "\n",
    "    training_data_path = f\"transformed_data/{channel}/train/{channel}.csv\"\n",
    "    testing_data_path = f\"transformed_data/{channel}/test/{channel}.csv\"\n",
    "    label_data_path = f\"transformed_data/{channel}/label/{channel}.csv\"\n",
    "    \n",
    "    X_transform_train = pd.read_csv(training_data_path).to_numpy()\n",
    "    X_transform_test =  pd.read_csv(testing_data_path).to_numpy()\n",
    "    y_test = pd.read_csv(label_data_path).to_numpy()\n",
    "\n",
    "    scaler = MinMaxScaler()\n",
    "    scaler.fit(X_transform_train)\n",
    "    X_fit_train = scaler.transform(X_transform_train)\n",
    "    X_fit_test = scaler.transform(X_transform_test)\n",
    "    \n",
    "    min_max_fitted_data[channel][\"train\"] = X_fit_train\n",
    "    min_max_fitted_data[channel][\"test\"] = X_fit_test\n",
    "    min_max_fitted_data[channel][\"label\"] = y_test\n",
    "    \n",
    "    print(\"train: \", channel, \"shape: \", X_fit_train.shape)\n",
    "    print(\"test: \", channel, \"shape: \", X_fit_test.shape)\n",
    "    print(\"label: \", channel, \"shape: \", y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "baf043f3-518d-4026-96b4-b50e79cfa290",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train:  T shape:  (431, 9996)\n",
      "test:  T shape:  (1292, 9996)\n",
      "label:  T shape:  (1292, 1)\n",
      "train:  G shape:  (793, 9996)\n",
      "test:  G shape:  (2405, 9996)\n",
      "label:  G shape:  (2405, 1)\n",
      "train:  S shape:  (141, 9996)\n",
      "test:  S shape:  (367, 9996)\n",
      "label:  S shape:  (367, 1)\n",
      "train:  P shape:  (703, 9996)\n",
      "test:  P shape:  (2056, 9996)\n",
      "label:  P shape:  (2056, 1)\n",
      "train:  D shape:  (1445, 9996)\n",
      "test:  D shape:  (4789, 9996)\n",
      "label:  D shape:  (4789, 1)\n",
      "train:  F shape:  (432, 9996)\n",
      "test:  F shape:  (1281, 9996)\n",
      "label:  F shape:  (1281, 1)\n",
      "train:  R shape:  (144, 9996)\n",
      "test:  R shape:  (363, 9996)\n",
      "label:  R shape:  (363, 1)\n",
      "train:  A shape:  (842, 9996)\n",
      "test:  A shape:  (3374, 9996)\n",
      "label:  A shape:  (3374, 1)\n",
      "train:  E shape:  (1867, 9996)\n",
      "test:  E shape:  (5486, 9996)\n",
      "label:  E shape:  (5486, 1)\n",
      "train:  B shape:  (122, 9996)\n",
      "test:  B shape:  (403, 9996)\n",
      "label:  B shape:  (403, 1)\n"
     ]
    }
   ],
   "source": [
    "standard_fitted_data = {}\n",
    "\n",
    "for channel in channel_names: \n",
    "    standard_fitted_data[channel] = {}\n",
    "\n",
    "    training_data_path = f\"transformed_data/{channel}/train/{channel}.csv\"\n",
    "    testing_data_path = f\"transformed_data/{channel}/test/{channel}.csv\"\n",
    "    label_data_path = f\"transformed_data/{channel}/label/{channel}.csv\"\n",
    "    \n",
    "    X_transform_train = pd.read_csv(training_data_path).to_numpy()\n",
    "    X_transform_test =  pd.read_csv(testing_data_path).to_numpy()\n",
    "    y_test = pd.read_csv(label_data_path).to_numpy()\n",
    "\n",
    "    scaler = StandardScaler()\n",
    "    scaler.fit(X_transform_train)\n",
    "    X_fit_train = scaler.transform(X_transform_train)\n",
    "    X_fit_test = scaler.transform(X_transform_test)\n",
    "    \n",
    "    standard_fitted_data[channel][\"train\"] = X_fit_train\n",
    "    standard_fitted_data[channel][\"test\"] = X_fit_test\n",
    "    standard_fitted_data[channel][\"label\"] = y_test\n",
    "    \n",
    "    print(\"train: \", channel, \"shape: \", X_fit_train.shape)\n",
    "    print(\"test: \", channel, \"shape: \", X_fit_test.shape)\n",
    "    print(\"label: \", channel, \"shape: \", y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d722ab9f-a61f-4f36-8347-a54434153f8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# performance bad for channels B, R, and S due to their small training data size\n",
    "# nu - controls boundary tightness (Smaller nu → tighter boundary → fewer false positives, Larger nu → looser boundary → higher recall)\n",
    "# threshold\t- converts scores (anomaly / normal)\n",
    "\n",
    "# Large (1000+ windows/channel)\tMostly clean\t0.01 – 0.02\n",
    "# Medium (hundreds of windows)\tMostly clean\t0.02 – 0.05\n",
    "# Small or noisy\tSome anomalies in training\t0.05 – 0.1\n",
    "#tighter nu makes more sense as the training data is supposed to have only normal data - needs confirmation at this point in time \n",
    "\n",
    "anomaly_rate = []\n",
    "for channel in transformed_data: \n",
    "    anomaly_count = 0\n",
    "    for label in min_max_fitted_data[channel][\"label\"]:\n",
    "        if label == 1:\n",
    "            anomaly_count += 1\n",
    "    anomaly_rate.append(anomaly_count / len(min_max_fitted_data[channel][\"label\"]))\n",
    "    \n",
    "print(anomaly_rate)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "183b7ba3-ab8b-4f27-af59-6786a12b5141",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(threshold, decision_scores):\n",
    "    y_pred = []\n",
    "    for score in decision_scores: \n",
    "        if score < threshold: \n",
    "            y_pred.append(1)\n",
    "        else:\n",
    "            y_pred.append(0)\n",
    "    return np.array(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "c299bcd5-4795-4e06-a8de-cf0c38e70a35",
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_class_svm(channel_data, channel):\n",
    "    print(\"channel:\", channel)\n",
    "    clf = OneClassSVM().fit(channel_data[\"train\"])\n",
    "    decision_scores = clf.decision_function(channel_data[\"test\"])\n",
    "    \n",
    "    thresholds = []\n",
    "    for score in decision_scores: \n",
    "        if score < 0:\n",
    "            thresholds.append(score)\n",
    "    \n",
    "    best_f1_score = 0\n",
    "    best_recall_score = 0\n",
    "    best_thresholds = []\n",
    "    best_threshold = 0\n",
    "\n",
    "    for th in thresholds:\n",
    "        y_pred = predict(th, decision_scores)\n",
    "        recall_1 = recall_score(channel_data[\"label\"], y_pred, pos_label=1)\n",
    "        if best_recall_score <= recall_1:\n",
    "            best_recall_score = recall_1\n",
    "            best_thresholds.append(th) \n",
    "    \n",
    "    for th in best_thresholds:\n",
    "        y_pred = predict(th, decision_scores)\n",
    "        f1 = f1_score(channel_data[\"label\"], y_pred)\n",
    "        if (best_f1_score <= f1):\n",
    "            best_f1_score = f1\n",
    "            best_threshold = th\n",
    "    \n",
    "    y_test = channel_data[\"label\"]\n",
    "    y_pred = predict(best_threshold, decision_scores)\n",
    "    print(\"best_threshold: \", best_threshold)\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    precision = precision_score(y_test, y_pred, average='weighted')\n",
    "    print(\"FDR:\", 1 - precision)\n",
    "    c_m = confusion_matrix(y_test, y_pred)\n",
    "    print(c_m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "207f134b-c3af-4e7b-9e60-df31cec0c957",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "channel: T\n",
      "best_threshold:  -0.1341484509441102\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.58      0.68      1103\n",
      "           1       0.10      0.27      0.14       189\n",
      "\n",
      "    accuracy                           0.53      1292\n",
      "   macro avg       0.46      0.42      0.41      1292\n",
      "weighted avg       0.72      0.53      0.60      1292\n",
      "\n",
      "FDR: 0.2840950515639118\n",
      "[[636 467]\n",
      " [138  51]]\n",
      "channel: G\n",
      "best_threshold:  -31.547416235253593\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.88      0.93      2354\n",
      "           1       0.04      0.25      0.08        51\n",
      "\n",
      "    accuracy                           0.87      2405\n",
      "   macro avg       0.51      0.57      0.50      2405\n",
      "weighted avg       0.96      0.87      0.91      2405\n",
      "\n",
      "FDR: 0.03786427199836684\n",
      "[[2075  279]\n",
      " [  38   13]]\n",
      "channel: S\n",
      "best_threshold:  -2.1037513616133356\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.87      0.91       342\n",
      "           1       0.26      0.64      0.37        25\n",
      "\n",
      "    accuracy                           0.85       367\n",
      "   macro avg       0.61      0.75      0.64       367\n",
      "weighted avg       0.92      0.85      0.88       367\n",
      "\n",
      "FDR: 0.07803866587319552\n",
      "[[296  46]\n",
      " [  9  16]]\n",
      "channel: P\n",
      "best_threshold:  -12.106163193759642\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.86      0.87      1761\n",
      "           1       0.29      0.33      0.31       295\n",
      "\n",
      "    accuracy                           0.79      2056\n",
      "   macro avg       0.59      0.60      0.59      2056\n",
      "weighted avg       0.80      0.79      0.79      2056\n",
      "\n",
      "FDR: 0.20122400266509644\n",
      "[[1523  238]\n",
      " [ 199   96]]\n",
      "channel: D\n",
      "best_threshold:  -0.039779018254876064\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.57      0.69      3705\n",
      "           1       0.33      0.71      0.45      1084\n",
      "\n",
      "    accuracy                           0.61      4789\n",
      "   macro avg       0.60      0.64      0.57      4789\n",
      "weighted avg       0.75      0.61      0.64      4789\n",
      "\n",
      "FDR: 0.25054551384048973\n",
      "[[2128 1577]\n",
      " [ 311  773]]\n",
      "channel: F\n",
      "best_threshold:  -0.04602681084930538\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.28      0.42      1118\n",
      "           1       0.11      0.60      0.18       163\n",
      "\n",
      "    accuracy                           0.32      1281\n",
      "   macro avg       0.47      0.44      0.30      1281\n",
      "weighted avg       0.74      0.32      0.39      1281\n",
      "\n",
      "FDR: 0.2634892405250566\n",
      "[[318 800]\n",
      " [ 66  97]]\n",
      "channel: R\n",
      "best_threshold:  -50.57460621496655\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99       356\n",
      "           1       0.40      0.29      0.33         7\n",
      "\n",
      "    accuracy                           0.98       363\n",
      "   macro avg       0.69      0.64      0.66       363\n",
      "weighted avg       0.97      0.98      0.98       363\n",
      "\n",
      "FDR: 0.025267402311587195\n",
      "[[353   3]\n",
      " [  5   2]]\n",
      "channel: A\n",
      "best_threshold:  -0.03245240436534402\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.38      0.51      2818\n",
      "           1       0.11      0.37      0.16       556\n",
      "\n",
      "    accuracy                           0.38      3374\n",
      "   macro avg       0.43      0.38      0.34      3374\n",
      "weighted avg       0.65      0.38      0.45      3374\n",
      "\n",
      "FDR: 0.35205368454435715\n",
      "[[1078 1740]\n",
      " [ 350  206]]\n",
      "channel: E\n",
      "best_threshold:  -0.12117374216228427\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.56      0.70      4882\n",
      "           1       0.16      0.67      0.26       604\n",
      "\n",
      "    accuracy                           0.57      5486\n",
      "   macro avg       0.55      0.62      0.48      5486\n",
      "weighted avg       0.85      0.57      0.65      5486\n",
      "\n",
      "FDR: 0.1522365568772288\n",
      "[[2739 2143]\n",
      " [ 197  407]]\n",
      "channel: B\n",
      "best_threshold:  -32.95308046162526\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.57      0.73       397\n",
      "           1       0.03      1.00      0.07         6\n",
      "\n",
      "    accuracy                           0.58       403\n",
      "   macro avg       0.52      0.78      0.40       403\n",
      "weighted avg       0.99      0.58      0.72       403\n",
      "\n",
      "FDR: 0.014383648063254428\n",
      "[[226 171]\n",
      " [  0   6]]\n"
     ]
    }
   ],
   "source": [
    "for channel in standard_fitted_data:\n",
    "    one_class_svm(standard_fitted_data[channel], channel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b42e4169-4a75-46d1-942c-75e811744528",
   "metadata": {},
   "outputs": [],
   "source": [
    "for channel in min_max_fitted_data:\n",
    "    one_class_svm(min_max_fitted_data[channel], channel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "36fafb8e-9f0e-4cd6-b18d-d1b4902bda29",
   "metadata": {},
   "outputs": [],
   "source": [
    "def isolation_forest(channel_data, channel):\n",
    "    print(\"channel:\", channel)\n",
    "    clf = IsolationForest(contamination = 0.5, random_state=42, n_jobs=-1).fit(channel_data[\"train\"])\n",
    "    decision_scores = clf.decision_function(channel_data[\"test\"])\n",
    "    \n",
    "    thresholds = []\n",
    "    for score in decision_scores: \n",
    "        if score < 0:\n",
    "            thresholds.append(score)\n",
    "    \n",
    "    best_f1_score = 0\n",
    "    best_recall_score = 0\n",
    "    best_thresholds = []\n",
    "    best_threshold = 0\n",
    "\n",
    "    for th in thresholds:\n",
    "        y_pred = predict(th, decision_scores)\n",
    "        recall_1 = recall_score(channel_data[\"label\"], y_pred, pos_label=1)\n",
    "        if best_recall_score <= recall_1:\n",
    "            best_recall_score = recall_1\n",
    "            best_thresholds.append(th) \n",
    "    \n",
    "    for th in best_thresholds:\n",
    "        y_pred = predict(th, decision_scores)\n",
    "        f1 = f1_score(channel_data[\"label\"], y_pred)\n",
    "        if (best_f1_score <= f1):\n",
    "            best_f1_score = f1\n",
    "            best_threshold = th\n",
    "    \n",
    "    y_test = channel_data[\"label\"]\n",
    "    y_pred = predict(best_threshold, decision_scores)\n",
    "    # raw_y_pred = clf.predict(channel_data[\"test\"])\n",
    "    # y_pred = []\n",
    "    # for y in raw_y_pred:\n",
    "    #     if y == -1:\n",
    "    #         y_pred.append(1)\n",
    "    #     else:\n",
    "    #         y_pred.append(0)\n",
    "            \n",
    "    print(\"best_threshold: \", best_threshold)\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    precision = precision_score(y_test, y_pred, average='weighted')\n",
    "    print(\"FDR:\", 1 - precision)\n",
    "    c_m = confusion_matrix(y_test, y_pred)\n",
    "    print(c_m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "b7003185-2129-4e99-8fa6-bd5323a3b1e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "channel: T\n",
      "best_threshold:  -0.00013722055087511675\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.56      0.69      1103\n",
      "           1       0.19      0.60      0.29       189\n",
      "\n",
      "    accuracy                           0.57      1292\n",
      "   macro avg       0.54      0.58      0.49      1292\n",
      "weighted avg       0.79      0.57      0.63      1292\n",
      "\n",
      "FDR: 0.21047857950240767\n",
      "[[620 483]\n",
      " [ 75 114]]\n",
      "channel: G\n",
      "best_threshold:  -0.00023553628446976171\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.54      0.70      2354\n",
      "           1       0.02      0.51      0.04        51\n",
      "\n",
      "    accuracy                           0.54      2405\n",
      "   macro avg       0.50      0.53      0.37      2405\n",
      "weighted avg       0.96      0.54      0.68      2405\n",
      "\n",
      "FDR: 0.03954476717361499\n",
      "[[1274 1080]\n",
      " [  25   26]]\n",
      "channel: S\n",
      "best_threshold:  -0.017497584179967884\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.69      0.80       342\n",
      "           1       0.12      0.60      0.21        25\n",
      "\n",
      "    accuracy                           0.69       367\n",
      "   macro avg       0.54      0.65      0.51       367\n",
      "weighted avg       0.90      0.69      0.76       367\n",
      "\n",
      "FDR: 0.09733284426744926\n",
      "[[237 105]\n",
      " [ 10  15]]\n",
      "channel: P\n",
      "best_threshold:  -0.00020906517041768824\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.68      0.76      1761\n",
      "           1       0.17      0.41      0.24       295\n",
      "\n",
      "    accuracy                           0.64      2056\n",
      "   macro avg       0.52      0.54      0.50      2056\n",
      "weighted avg       0.77      0.64      0.69      2056\n",
      "\n",
      "FDR: 0.2284915765413308\n",
      "[[1189  572]\n",
      " [ 175  120]]\n",
      "channel: D\n",
      "best_threshold:  -2.5170898582949075e-05\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.59      0.68      3705\n",
      "           1       0.27      0.50      0.35      1084\n",
      "\n",
      "    accuracy                           0.57      4789\n",
      "   macro avg       0.53      0.55      0.51      4789\n",
      "weighted avg       0.68      0.57      0.61      4789\n",
      "\n",
      "FDR: 0.31873769832772925\n",
      "[[2189 1516]\n",
      " [ 537  547]]\n",
      "channel: F\n",
      "best_threshold:  -0.12420983158090593\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.98      0.92      1118\n",
      "           1       0.16      0.02      0.04       163\n",
      "\n",
      "    accuracy                           0.86      1281\n",
      "   macro avg       0.52      0.50      0.48      1281\n",
      "weighted avg       0.78      0.86      0.81      1281\n",
      "\n",
      "FDR: 0.21736944166828265\n",
      "[[1097   21]\n",
      " [ 159    4]]\n",
      "channel: R\n",
      "best_threshold:  -0.007418045938179296\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.94      0.96       356\n",
      "           1       0.12      0.43      0.19         7\n",
      "\n",
      "    accuracy                           0.93       363\n",
      "   macro avg       0.55      0.68      0.58       363\n",
      "weighted avg       0.97      0.93      0.95       363\n",
      "\n",
      "FDR: 0.028575806477904475\n",
      "[[334  22]\n",
      " [  4   3]]\n",
      "channel: A\n",
      "best_threshold:  -0.007742067503208716\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.62      0.69      2818\n",
      "           1       0.02      0.03      0.02       556\n",
      "\n",
      "    accuracy                           0.53      3374\n",
      "   macro avg       0.39      0.33      0.36      3374\n",
      "weighted avg       0.64      0.53      0.58      3374\n",
      "\n",
      "FDR: 0.357316128214611\n",
      "[[1758 1060]\n",
      " [ 537   19]]\n",
      "channel: E\n",
      "best_threshold:  -2.035687361223726e-05\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.48      0.63      4882\n",
      "           1       0.14      0.67      0.23       604\n",
      "\n",
      "    accuracy                           0.50      5486\n",
      "   macro avg       0.53      0.57      0.43      5486\n",
      "weighted avg       0.84      0.50      0.58      5486\n",
      "\n",
      "FDR: 0.1649156614384778\n",
      "[[2323 2559]\n",
      " [ 198  406]]\n",
      "channel: B\n",
      "best_threshold:  -0.02948707208660928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.93      0.96       397\n",
      "           1       0.10      0.50      0.17         6\n",
      "\n",
      "    accuracy                           0.93       403\n",
      "   macro avg       0.55      0.72      0.57       403\n",
      "weighted avg       0.98      0.93      0.95       403\n",
      "\n",
      "FDR: 0.021250129834831766\n",
      "[[371  26]\n",
      " [  3   3]]\n"
     ]
    }
   ],
   "source": [
    "for channel in standard_fitted_data:\n",
    "    isolation_forest(standard_fitted_data[channel], channel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "baa41085-279e-46b1-b001-274dd234df28",
   "metadata": {},
   "outputs": [],
   "source": [
    "#LOF learns a reference density from X_train, new points are compared against training density\n",
    "def local_outlier_factor(channel_data, channel):\n",
    "    print(\"channel:\", channel)\n",
    "    clf = LocalOutlierFactor(n_neighbors=20, novelty=True)\n",
    "    clf.fit(channel_data[\"train\"])\n",
    "    decision_scores = clf.decision_function(channel_data[\"test\"])\n",
    "    \n",
    "    thresholds = []\n",
    "    for score in decision_scores: \n",
    "        if score < 0:\n",
    "            thresholds.append(score)\n",
    "    \n",
    "    best_f1_score = 0\n",
    "    best_recall_score = 0\n",
    "    best_thresholds = []\n",
    "    best_threshold = 0\n",
    "\n",
    "    for th in thresholds:\n",
    "        y_pred = predict(th, decision_scores)\n",
    "        recall_1 = recall_score(channel_data[\"label\"], y_pred, pos_label=1)\n",
    "        if best_recall_score <= recall_1:\n",
    "            best_recall_score = recall_1\n",
    "            best_thresholds.append(th) \n",
    "    \n",
    "    for th in best_thresholds:\n",
    "        y_pred = predict(th, decision_scores)\n",
    "        f1 = f1_score(channel_data[\"label\"], y_pred)\n",
    "        if (best_f1_score <= f1):\n",
    "            best_f1_score = f1\n",
    "            best_threshold = th\n",
    "    \n",
    "    y_test = channel_data[\"label\"]\n",
    "    y_pred = predict(best_threshold, decision_scores)\n",
    "    print(\"best_threshold: \", best_threshold)\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    precision = precision_score(y_test, y_pred, average='weighted')\n",
    "    print(\"FDR:\", 1 - precision)\n",
    "    c_m = confusion_matrix(y_test, y_pred)\n",
    "    print(c_m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "c7c42bea-6020-47ad-adbb-85dcf6bb4ae4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "channel: T\n",
      "best_threshold:  -0.7156425164396607\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.98      0.92      1103\n",
      "           1       0.31      0.04      0.07       189\n",
      "\n",
      "    accuracy                           0.85      1292\n",
      "   macro avg       0.58      0.51      0.50      1292\n",
      "weighted avg       0.78      0.85      0.79      1292\n",
      "\n",
      "FDR: 0.22332975729194537\n",
      "[[1085   18]\n",
      " [ 181    8]]\n",
      "channel: G\n",
      "best_threshold:  -0.030135612993663186\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.70      0.82      2354\n",
      "           1       0.04      0.57      0.07        51\n",
      "\n",
      "    accuracy                           0.70      2405\n",
      "   macro avg       0.51      0.63      0.45      2405\n",
      "weighted avg       0.97      0.70      0.80      2405\n",
      "\n",
      "FDR: 0.03330779844293352\n",
      "[[1643  711]\n",
      " [  22   29]]\n",
      "channel: S\n",
      "best_threshold:  -0.08878377204262122\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.97      0.97       342\n",
      "           1       0.54      0.52      0.53        25\n",
      "\n",
      "    accuracy                           0.94       367\n",
      "   macro avg       0.75      0.74      0.75       367\n",
      "weighted avg       0.94      0.94      0.94       367\n",
      "\n",
      "FDR: 0.06382383626864518\n",
      "[[331  11]\n",
      " [ 12  13]]\n",
      "channel: P\n",
      "best_threshold:  -0.0070200129821880175\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.93      0.90      1761\n",
      "           1       0.35      0.24      0.29       295\n",
      "\n",
      "    accuracy                           0.83      2056\n",
      "   macro avg       0.61      0.58      0.59      2056\n",
      "weighted avg       0.80      0.83      0.81      2056\n",
      "\n",
      "FDR: 0.19683912226743505\n",
      "[[1629  132]\n",
      " [ 224   71]]\n",
      "channel: D\n",
      "best_threshold:  -0.0015755707365225913\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.91      0.83      3705\n",
      "           1       0.21      0.08      0.12      1084\n",
      "\n",
      "    accuracy                           0.72      4789\n",
      "   macro avg       0.49      0.50      0.48      4789\n",
      "weighted avg       0.64      0.72      0.67      4789\n",
      "\n",
      "FDR: 0.3554917678633497\n",
      "[[3357  348]\n",
      " [ 992   92]]\n",
      "channel: F\n",
      "best_threshold:  -0.023287649200093963\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.77      0.83      1118\n",
      "           1       0.21      0.43      0.28       163\n",
      "\n",
      "    accuracy                           0.73      1281\n",
      "   macro avg       0.56      0.60      0.56      1281\n",
      "weighted avg       0.81      0.73      0.76      1281\n",
      "\n",
      "FDR: 0.18542977009429507\n",
      "[[859 259]\n",
      " [ 93  70]]\n",
      "channel: R\n",
      "best_threshold:  -202983561411.61176\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.05      0.10       356\n",
      "           1       0.02      1.00      0.04         7\n",
      "\n",
      "    accuracy                           0.07       363\n",
      "   macro avg       0.51      0.53      0.07       363\n",
      "weighted avg       0.98      0.07      0.10       363\n",
      "\n",
      "FDR: 0.01889248213358885\n",
      "[[ 18 338]\n",
      " [  0   7]]\n",
      "channel: A\n",
      "best_threshold:  -0.004551496026479196\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.64      0.73      2818\n",
      "           1       0.20      0.46      0.28       556\n",
      "\n",
      "    accuracy                           0.61      3374\n",
      "   macro avg       0.53      0.55      0.51      3374\n",
      "weighted avg       0.75      0.61      0.66      3374\n",
      "\n",
      "FDR: 0.24935994726573507\n",
      "[[1809 1009]\n",
      " [ 298  258]]\n",
      "channel: E\n",
      "best_threshold:  -0.012925130682067243\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.78      0.85      4882\n",
      "           1       0.23      0.53      0.33       604\n",
      "\n",
      "    accuracy                           0.76      5486\n",
      "   macro avg       0.58      0.66      0.59      5486\n",
      "weighted avg       0.85      0.76      0.79      5486\n",
      "\n",
      "FDR: 0.14513009988706416\n",
      "[[3828 1054]\n",
      " [ 281  323]]\n",
      "channel: B\n",
      "best_threshold:  -1193539316590.5916\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.63      0.77       397\n",
      "           1       0.04      1.00      0.08         6\n",
      "\n",
      "    accuracy                           0.64       403\n",
      "   macro avg       0.52      0.82      0.43       403\n",
      "weighted avg       0.99      0.64      0.76       403\n",
      "\n",
      "FDR: 0.014300639937312232\n",
      "[[251 146]\n",
      " [  0   6]]\n"
     ]
    }
   ],
   "source": [
    "for channel in standard_fitted_data:\n",
    "    local_outlier_factor(standard_fitted_data[channel], channel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "02e59535-55f0-45e5-953a-d979443cfa64",
   "metadata": {},
   "outputs": [],
   "source": [
    "#LOF learns a reference density from X_train, new points are compared against training density\n",
    "def ensemble_local_outlier_factor(channel_data, channel):\n",
    "    clf = LocalOutlierFactor(n_neighbors=20, novelty=True)\n",
    "    clf.fit(channel_data[\"train\"])\n",
    "    decision_scores = clf.decision_function(channel_data[\"test\"])\n",
    "    \n",
    "    thresholds = []\n",
    "    for score in decision_scores: \n",
    "        if score < 0:\n",
    "            thresholds.append(score)\n",
    "    \n",
    "    best_f1_score = 0\n",
    "    best_recall_score = 0\n",
    "    best_thresholds = []\n",
    "    best_threshold = 0\n",
    "\n",
    "    for th in thresholds:\n",
    "        y_pred = predict(th, decision_scores)\n",
    "        recall_1 = recall_score(channel_data[\"label\"], y_pred, pos_label=1)\n",
    "        if best_recall_score <= recall_1:\n",
    "            best_recall_score = recall_1\n",
    "            best_thresholds.append(th) \n",
    "    \n",
    "    for th in best_thresholds:\n",
    "        y_pred = predict(th, decision_scores)\n",
    "        f1 = f1_score(channel_data[\"label\"], y_pred)\n",
    "        if (best_f1_score <= f1):\n",
    "            best_f1_score = f1\n",
    "            best_threshold = th\n",
    "    \n",
    "    return predict(best_threshold, decision_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "6dd885e8-f592-4f7f-8291-2dca72912e88",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ensemble_isolation_forest(channel_data, channel):\n",
    "    clf = IsolationForest(contamination = 0.5, random_state=42, n_jobs=-1).fit(channel_data[\"train\"])\n",
    "    decision_scores = clf.decision_function(channel_data[\"test\"])\n",
    "    \n",
    "    thresholds = []\n",
    "    for score in decision_scores: \n",
    "        if score < 0:\n",
    "            thresholds.append(score)\n",
    "    \n",
    "    best_f1_score = 0\n",
    "    best_recall_score = 0\n",
    "    best_thresholds = []\n",
    "    best_threshold = 0\n",
    "\n",
    "    for th in thresholds:\n",
    "        y_pred = predict(th, decision_scores)\n",
    "        recall_1 = recall_score(channel_data[\"label\"], y_pred, pos_label=1)\n",
    "        if best_recall_score <= recall_1:\n",
    "            best_recall_score = recall_1\n",
    "            best_thresholds.append(th) \n",
    "    \n",
    "    for th in best_thresholds:\n",
    "        y_pred = predict(th, decision_scores)\n",
    "        f1 = f1_score(channel_data[\"label\"], y_pred)\n",
    "        if (best_f1_score <= f1):\n",
    "            best_f1_score = f1\n",
    "            best_threshold = th\n",
    "\n",
    "    return predict(best_threshold, decision_scores)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "57684881-eae2-41a5-86cc-df8c0b887dc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ensemble_one_class_svm(channel_data, channel):\n",
    "    clf = OneClassSVM().fit(channel_data[\"train\"])\n",
    "    decision_scores = clf.decision_function(channel_data[\"test\"])\n",
    "    \n",
    "    thresholds = []\n",
    "    for score in decision_scores: \n",
    "        if score < 0:\n",
    "            thresholds.append(score)\n",
    "    \n",
    "    best_f1_score = 0\n",
    "    best_recall_score = 0\n",
    "    best_thresholds = []\n",
    "    best_threshold = 0\n",
    "\n",
    "    for th in thresholds:\n",
    "        y_pred = predict(th, decision_scores)\n",
    "        recall_1 = recall_score(channel_data[\"label\"], y_pred, pos_label=1)\n",
    "        if best_recall_score <= recall_1:\n",
    "            best_recall_score = recall_1\n",
    "            best_thresholds.append(th) \n",
    "        \n",
    "    for th in best_thresholds:\n",
    "        y_pred = predict(th, decision_scores)\n",
    "        f1 = f1_score(channel_data[\"label\"], y_pred)\n",
    "        if (best_f1_score <= f1):\n",
    "            best_f1_score = f1\n",
    "            best_threshold = th\n",
    "    \n",
    "    return predict(best_threshold, decision_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48f7d7e1-4479-493d-9695-b446072ab73a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "channel:  T\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.84      0.85      1103\n",
      "           1       0.22      0.25      0.23       189\n",
      "\n",
      "    accuracy                           0.76      1292\n",
      "   macro avg       0.54      0.55      0.54      1292\n",
      "weighted avg       0.77      0.76      0.76      1292\n",
      "\n",
      "FDR: 0.22740166460081734\n",
      "[[928 175]\n",
      " [141  48]]\n",
      "channel:  G\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.86      0.92      2354\n",
      "           1       0.04      0.29      0.07        51\n",
      "\n",
      "    accuracy                           0.85      2405\n",
      "   macro avg       0.51      0.58      0.50      2405\n",
      "weighted avg       0.96      0.85      0.90      2405\n",
      "\n",
      "FDR: 0.03743281569867829\n",
      "[[2020  334]\n",
      " [  36   15]]\n",
      "channel:  S\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.87      0.92       342\n",
      "           1       0.25      0.60      0.36        25\n",
      "\n",
      "    accuracy                           0.85       367\n",
      "   macro avg       0.61      0.74      0.64       367\n",
      "weighted avg       0.92      0.85      0.88       367\n",
      "\n",
      "FDR: 0.08105712234470364\n",
      "[[298  44]\n",
      " [ 10  15]]\n",
      "channel:  P\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.86      0.87      1761\n",
      "           1       0.27      0.31      0.29       295\n",
      "\n",
      "    accuracy                           0.78      2056\n",
      "   macro avg       0.58      0.58      0.58      2056\n",
      "weighted avg       0.79      0.78      0.79      2056\n",
      "\n",
      "FDR: 0.20632771689639196\n",
      "[[1511  250]\n",
      " [ 203   92]]\n",
      "channel:  D\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.67      0.73      3705\n",
      "           1       0.27      0.42      0.33      1084\n",
      "\n",
      "    accuracy                           0.61      4789\n",
      "   macro avg       0.53      0.54      0.53      4789\n",
      "weighted avg       0.68      0.61      0.64      4789\n",
      "\n",
      "FDR: 0.3229077420359162\n",
      "[[2468 1237]\n",
      " [ 630  454]]\n",
      "channel:  F\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.76      0.83      1118\n",
      "           1       0.21      0.43      0.28       163\n",
      "\n",
      "    accuracy                           0.72      1281\n",
      "   macro avg       0.56      0.60      0.55      1281\n",
      "weighted avg       0.81      0.72      0.76      1281\n",
      "\n",
      "FDR: 0.18611471578892214\n",
      "[[855 263]\n",
      " [ 93  70]]\n",
      "channel:  R\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.98      0.99       356\n",
      "           1       0.33      0.43      0.38         7\n",
      "\n",
      "    accuracy                           0.97       363\n",
      "   macro avg       0.66      0.71      0.68       363\n",
      "weighted avg       0.98      0.97      0.97       363\n",
      "\n",
      "FDR: 0.0239373706245819\n",
      "[[350   6]\n",
      " [  4   3]]\n",
      "channel:  A\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.48      0.59      2818\n",
      "           1       0.08      0.24      0.12       556\n",
      "\n",
      "    accuracy                           0.44      3374\n",
      "   macro avg       0.42      0.36      0.35      3374\n",
      "weighted avg       0.65      0.44      0.51      3374\n",
      "\n",
      "FDR: 0.351301338681401\n",
      "[[1346 1472]\n",
      " [ 424  132]]\n"
     ]
    }
   ],
   "source": [
    "for channel in standard_fitted_data: \n",
    "    y_pred_one_class_svm = ensemble_one_class_svm(standard_fitted_data[channel], channel)\n",
    "    y_pred_isolation_forest = ensemble_isolation_forest(standard_fitted_data[channel], channel)\n",
    "    y_pred_local_outlier_factor = ensemble_local_outlier_factor(standard_fitted_data[channel], channel)\n",
    "\n",
    "    y_pred = []\n",
    "    for i in range(len(y_pred_one_class_svm)): \n",
    "        ensemble = y_pred_one_class_svm[i] + y_pred_isolation_forest[i] + y_pred_local_outlier_factor[i]\n",
    "        if ensemble >= 2: \n",
    "            y_pred.append(1)\n",
    "        else:\n",
    "            y_pred.append(0)\n",
    "    print(\"channel: \",channel)\n",
    "    y_test = (standard_fitted_data[channel][\"label\"])\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    precision = precision_score(y_test, y_pred, average='weighted')\n",
    "    print(\"FDR:\", 1 - precision)\n",
    "    c_m = confusion_matrix(y_test, y_pred)\n",
    "    print(c_m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea65a59a-1995-45cb-91f2-0074973e0170",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10",
   "language": "python",
   "name": "python-3.10"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
