{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e2cfce4d-82c7-43cf-a818-594b73f5d325",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import necessary packages\n",
    "from pathlib import Path\n",
    "import os\n",
    "import ast\n",
    "import shutil\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.metrics import classification_report, confusion_matrix, ConfusionMatrixDisplay, precision_score\n",
    "from sklearn.svm import OneClassSVM\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "from sktime.transformations.panel.rocket import (\n",
    "    MiniRocket,\n",
    "    MiniRocketMultivariate,\n",
    "    MiniRocketMultivariateVariable,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ecfa9908-f807-42be-b37c-be84a9b87ec1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#collection of dataset information for each telemetry data \n",
    "training_dfs = []\n",
    "test_dfs = []\n",
    "\n",
    "training_df = []\n",
    "test_df = []\n",
    "\n",
    "file_names = []\n",
    "\n",
    "label_df = pd.read_csv(\"labeled_anomalies.csv\")\n",
    "\n",
    "train_data_path = \"npy_train\" \n",
    "test_data_path = \"npy_test\" \n",
    "\n",
    "os.makedirs(\"raw_train\", exist_ok=True)\n",
    "os.makedirs(\"raw_test\", exist_ok=True)\n",
    "\n",
    "index = 0\n",
    "for root, _, files in os.walk(train_data_path):\n",
    "    for file in files:\n",
    "        example_path = os.path.join(root, file)\n",
    "        filename = Path(example_path).stem\n",
    "        \n",
    "        row_indices = label_df[label_df['chan_id'] == filename].index.tolist()\n",
    "        if not row_indices:\n",
    "            continue\n",
    "        spacecraft = label_df.loc[row_indices[0], 'spacecraft']\n",
    "        \n",
    "        if (spacecraft == \"SMAP\"): \n",
    "            data = np.load(example_path)\n",
    "            df = pd.DataFrame(data)\n",
    "            print(\"(train) df: \", filename, df.shape, \"index: \", index)\n",
    "            df.to_csv(f\"raw_train/{filename}.csv\", index=False)\n",
    "            training_dfs.append(df) \n",
    "            index += 1\n",
    "\n",
    "index = 0\n",
    "for root, _, files in os.walk(test_data_path):\n",
    "    for file in files:\n",
    "        example_path = os.path.join(root, file)\n",
    "        filename = Path(example_path).stem\n",
    "        \n",
    "        row_indices = label_df[label_df['chan_id'] == filename].index.tolist()\n",
    "        if not row_indices:\n",
    "            continue\n",
    "        spacecraft = label_df.loc[row_indices[0], 'spacecraft']\n",
    "        \n",
    "        if (spacecraft == \"SMAP\"): \n",
    "            data = np.load(example_path)\n",
    "            df = pd.DataFrame(data)\n",
    "            print(\"(test) df: \", filename, df.shape, \"index: \", index)\n",
    "            df.to_csv(f\"raw_test/{filename}.csv\", index=False)\n",
    "            test_dfs.append(df) \n",
    "            file_names.append(filename)\n",
    "            \n",
    "            index += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d49f058b-3a33-4b1a-a147-81c717e1645e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data():\n",
    "    training_dfs = {}\n",
    "    test_dfs = {}\n",
    "    file_names = {\"train\": {}, \"test\": {}}\n",
    "    label_df = pd.read_csv(\"labeled_anomalies.csv\")\n",
    "    train_data_path = \"raw_train\" \n",
    "    test_data_path = \"raw_test\" \n",
    "    \n",
    "    for root, _, files in os.walk(train_data_path):\n",
    "        for file in files:\n",
    "            example_path = os.path.join(root, file)\n",
    "            filename = Path(example_path).stem\n",
    "            df = pd.read_csv(example_path)\n",
    "            channel = filename[0]            \n",
    "            if (training_dfs.get(channel) == None):\n",
    "                training_dfs[channel] = []\n",
    "                file_names[\"train\"][channel] = []\n",
    "                training_dfs[channel].append(df)\n",
    "                file_names[\"train\"][channel].append(filename)\n",
    "            else:\n",
    "                training_dfs[channel].append(df)\n",
    "                file_names[\"train\"][channel].append(filename)\n",
    "    \n",
    "    for root, _, files in os.walk(test_data_path):\n",
    "        for file in files:\n",
    "            example_path = os.path.join(root, file)\n",
    "            filename = Path(example_path).stem\n",
    "            df = pd.read_csv(example_path)\n",
    "            channel = filename[0]\n",
    "            if (test_dfs.get(channel) == None):\n",
    "                test_dfs[channel] = []\n",
    "                file_names[\"test\"][channel] = []\n",
    "                test_dfs[channel].append(df)\n",
    "                file_names[\"test\"][channel].append(filename)\n",
    "            else:\n",
    "                test_dfs[channel].append(df)\n",
    "                file_names[\"test\"][channel].append(filename)\n",
    "\n",
    "    return (training_dfs, test_dfs, label_df, file_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b7af7343-fd52-45db-9b3a-0cf2358da275",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_windows(training_dfs, test_dfs, window_size, window_overlap, label_df, file_names):\n",
    "    training_data = {}\n",
    "    test_data = {}\n",
    "    label_data = {}\n",
    "    \n",
    "    for channel in training_dfs.keys():\n",
    "        training_data[channel] = []\n",
    "        for df in training_dfs[channel]: \n",
    "            for i in range(0, len(df), window_overlap):\n",
    "                window = []\n",
    "                if i + window_size > len(df): \n",
    "                    window = df.iloc[-window_size:].to_numpy().tolist()\n",
    "                else: \n",
    "                    window = df.iloc[i:i + window_size].to_numpy().tolist()\n",
    "                np_window = np.array(window)\n",
    "                transposed_window = np_window.T\n",
    "                normal_window = transposed_window.tolist() \n",
    "                training_data[channel].append(normal_window)\n",
    "                \n",
    "    for channel in test_dfs.keys():\n",
    "        test_data[channel] = []\n",
    "        label_data[channel] = []\n",
    "        for i in range(len(test_dfs[channel])):\n",
    "            df = test_dfs[channel][i]\n",
    "            for j in range(0, len(df), window_overlap):\n",
    "                window = []\n",
    "                if j + window_size > len(df): \n",
    "                    window = df.iloc[-window_size:].to_numpy().tolist()\n",
    "                else: \n",
    "                    window = df.iloc[j:j + window_size].to_numpy().tolist()\n",
    "                row_indices = label_df[label_df[\"chan_id\"] == file_names[\"test\"][channel][i]].index.tolist()\n",
    "                \n",
    "                if not row_indices:\n",
    "                    continue\n",
    "\n",
    "                anomaly_sequence = label_df.loc[row_indices[0], 'anomaly_sequences']\n",
    "                anomaly_sequence = ast.literal_eval(anomaly_sequence)\n",
    "                labeled = False\n",
    "                for anomalies in anomaly_sequence:\n",
    "                    if (not(anomalies[1] <= j or anomalies[0] >= j + window_size)) and labeled == False:\n",
    "                        label_data[channel].append(1)\n",
    "                        labeled = True\n",
    "                if labeled == False:\n",
    "                    label_data[channel].append(0)\n",
    "                np_window = np.array(window)\n",
    "                transposed_window = np_window.T\n",
    "                normal_window = transposed_window.tolist() \n",
    "                test_data[channel].append(normal_window)\n",
    "                \n",
    "    return (training_data, test_data, label_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d0c50c2-a610-488e-8e78-a346d393de6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "window_size = 60 \n",
    "window_overlap = 20\n",
    "training_dfs, test_dfs, label_df, file_names = get_data()\n",
    "\n",
    "X_train_collection, X_test_collection, y_test_collection = create_windows(training_dfs, test_dfs, window_size, window_overlap, label_df, file_names)\n",
    "\n",
    "os.makedirs(\"training_data\", exist_ok=True)\n",
    "os.makedirs(\"testing_data\", exist_ok=True)\n",
    "os.makedirs(\"label_data\", exist_ok=True)\n",
    "\n",
    "for channel in X_train_collection: \n",
    "    X_train = np.array(X_train_collection[channel])\n",
    "    print(\"train\" ,X_train.shape)\n",
    "    # train_df = pd.DataFrame(X_train)\n",
    "    # train_df.to_csv(f\"training_data{channel}.csv\", index=False)\n",
    "    \n",
    "for channel in X_test_collection: \n",
    "    X_test = np.array(X_test_collection[channel])\n",
    "    # test_df = pd.DataFrame(X_test)\n",
    "    # test_df.to_csv(f\"testing_data/{channel}.csv\", index=False)\n",
    "    print(\"test\" ,X_test.shape)\n",
    "for channel in y_test_collection: \n",
    "    y_test =  np.array(y_test_collection[channel])\n",
    "    # true_label_df = pd.DataFrame(y_test)\n",
    "    # true_label_df.to_csv(f\"label_data/{channel}.csv\", index=False)\n",
    "    print(\"label\" ,y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8916e30a-ea28-467c-a281-986881bd9da8",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_transform_train_collection = {}\n",
    "X_transform_test_collection = {}\n",
    "y_true_label_collection = {}\n",
    "\n",
    "for channel in X_train_collection: \n",
    "    minirocket = MiniRocketMultivariate(n_jobs = 2, random_state = 42) \n",
    "    X_train = np.array(X_train_collection[channel])\n",
    "    if (X_test_collection.get(channel) is None or y_test_collection.get(channel) is None):  \n",
    "        continue\n",
    "    X_test = np.array(X_test_collection[channel])\n",
    "    minirocket.fit(X_train)\n",
    "    X_transform_train = minirocket.transform(X_train)\n",
    "    X_transform_test = minirocket.transform(X_test)\n",
    "    X_transform_train_collection[channel] = X_transform_train\n",
    "    X_transform_test_collection[channel] = X_transform_test\n",
    "    print(\"channel: \", channel)\n",
    "    print(\"(transformed train): \" ,X_transform_train.shape)\n",
    "    print(\"(transformed test): \" ,X_transform_test.shape)\n",
    "\n",
    "for channel in y_test_collection: \n",
    "    y_test =  np.array(y_test_collection[channel])\n",
    "    y_true_label_collection[channel] = y_test\n",
    "    print(\"channel: \", channel)\n",
    "    print(\"label\" ,y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e38d02f6-6973-4871-b93e-2e7fcba2727b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_fit_train_collection = {}\n",
    "X_fit_test_collection = {}\n",
    "\n",
    "for channel in X_transform_train_collection: \n",
    "    X_transform_train = X_transform_train_collection[channel]\n",
    "    X_transform_test = X_transform_test_collection[channel]\n",
    "    scaler = MinMaxScaler()\n",
    "    scaler.fit(X_transform_train)\n",
    "    X_fit_train = scaler.transform(X_transform_train)\n",
    "    X_fit_test = scaler.transform(X_transform_test)\n",
    "    \n",
    "    X_fit_train_collection[channel] = X_fit_train\n",
    "    X_fit_test_collection[channel] = X_fit_test\n",
    "    print(\"channel: \", channel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c299bcd5-4795-4e06-a8de-cf0c38e70a35",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = OneClassSVM(gamma='auto').fit(X_fit_train_collection[\"A\"])\n",
    "y_pred = clf.predict(X_fit_test)\n",
    "\n",
    "# print(\"params: \", grid_search.best_params_)\n",
    "# print(\"score: \", best_svc_model.score(fit_X_test, y_test))\n",
    "print(classification_report(y_test, y_pred))\n",
    "precision = precision_score(y_test, y_pred, average='weighted')\n",
    "print(\"FDR:\", 1 - precision)\n",
    "c_m = confusion_matrix(y_test, y_pred)\n",
    "print(c_m)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=c_m)\n",
    "disp.plot(cmap='Blues')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d08861dd-682d-4d8a-b578-231ea5f35dc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = IsolationForest(random_state=0).fit(X_transform_train_collection[\"A\"])\n",
    "y_pred = clf.predict(X_transform_test)\n",
    "\n",
    "# print(\"params: \", grid_search.best_params_)\n",
    "# print(\"score: \", best_svc_model.score(fit_X_test, y_test))\n",
    "print(classification_report(y_test, y_pred))\n",
    "precision = precision_score(y_test, y_pred, average='weighted')\n",
    "print(\"FDR:\", 1 - precision)\n",
    "c_m = confusion_matrix(y_test, y_pred)\n",
    "print(c_m)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=c_m)\n",
    "disp.plot(cmap='Blues')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baa41085-279e-46b1-b001-274dd234df28",
   "metadata": {},
   "outputs": [],
   "source": [
    "#implement KNN\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "382a662e-ebbd-4d17-a69a-3ce18e20f912",
   "metadata": {},
   "outputs": [],
   "source": [
    "#implement GridSearch \n",
    "\n",
    "# svc = SVC(class_weight='balanced', random_state=42)\n",
    "# param_grid = {\n",
    "#         'kernel': ['poly'],\n",
    "#         'degree': [2, 3, 4],\n",
    "#         'C': [1, 10, 100, 1000],\n",
    "#         'gamma': [0.0001, 0.001, 0.01, 0.1]\n",
    "#         }\n",
    "# grid_search = GridSearchCV(estimator=svc, param_grid=param_grid, scoring='f1_weighted', cv=10, n_jobs=-1)\n",
    "# grid_search.fit(fit_X_train, y_train)\n",
    "\n",
    "# best_svc_model = grid_search.best_estimator_\n",
    "# test_accuracy = best_svc_model.score(fit_X_test, y_test)\n",
    "# y_pred = best_svc_model.predict(fit_X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa9f74c9-85c8-4701-b418-3d1378766f68",
   "metadata": {},
   "outputs": [],
   "source": [
    "#implement grid search for unsupervised learning"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10",
   "language": "python",
   "name": "python-3.10"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
