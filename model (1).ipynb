{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e2cfce4d-82c7-43cf-a818-594b73f5d325",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import necessary packages\n",
    "from pathlib import Path\n",
    "import os\n",
    "import ast\n",
    "import shutil\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.metrics import classification_report, confusion_matrix, ConfusionMatrixDisplay, precision_score, recall_score, f1_score\n",
    "from sklearn.svm import OneClassSVM\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "from sklearn.neighbors import LocalOutlierFactor\n",
    "from sktime.transformations.panel.rocket import (\n",
    "    MiniRocket,\n",
    "    MiniRocketMultivariate,\n",
    "    MiniRocketMultivariateVariable,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ecfa9908-f807-42be-b37c-be84a9b87ec1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#collection of dataset information for each telemetry data \n",
    "training_dfs = []\n",
    "test_dfs = []\n",
    "\n",
    "training_df = []\n",
    "test_df = []\n",
    "\n",
    "file_names = []\n",
    "\n",
    "label_df = pd.read_csv(\"labeled_anomalies.csv\")\n",
    "\n",
    "train_data_path = \"npy_train\" \n",
    "test_data_path = \"npy_test\" \n",
    "\n",
    "os.makedirs(\"raw_train\", exist_ok=True)\n",
    "os.makedirs(\"raw_test\", exist_ok=True)\n",
    "\n",
    "index = 0\n",
    "for root, _, files in os.walk(train_data_path):\n",
    "    for file in files:\n",
    "        example_path = os.path.join(root, file)\n",
    "        filename = Path(example_path).stem\n",
    "        \n",
    "        row_indices = label_df[label_df['chan_id'] == filename].index.tolist()\n",
    "        if not row_indices:\n",
    "            continue\n",
    "        spacecraft = label_df.loc[row_indices[0], 'spacecraft']\n",
    "        \n",
    "        if (spacecraft == \"SMAP\"): \n",
    "            data = np.load(example_path)\n",
    "            df = pd.DataFrame(data)\n",
    "            print(\"(train) df: \", filename, df.shape, \"index: \", index)\n",
    "            df.to_csv(f\"raw_train/{filename}.csv\", index=False)\n",
    "            training_dfs.append(df) \n",
    "            index += 1\n",
    "\n",
    "index = 0\n",
    "for root, _, files in os.walk(test_data_path):\n",
    "    for file in files:\n",
    "        example_path = os.path.join(root, file)\n",
    "        filename = Path(example_path).stem\n",
    "        \n",
    "        row_indices = label_df[label_df['chan_id'] == filename].index.tolist()\n",
    "        if not row_indices:\n",
    "            continue\n",
    "        spacecraft = label_df.loc[row_indices[0], 'spacecraft']\n",
    "        \n",
    "        if (spacecraft == \"SMAP\"): \n",
    "            data = np.load(example_path)\n",
    "            df = pd.DataFrame(data)\n",
    "            print(\"(test) df: \", filename, df.shape, \"index: \", index)\n",
    "            df.to_csv(f\"raw_test/{filename}.csv\", index=False)\n",
    "            test_dfs.append(df) \n",
    "            file_names.append(filename)\n",
    "            \n",
    "            index += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d49f058b-3a33-4b1a-a147-81c717e1645e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data():\n",
    "    training_dfs = {}\n",
    "    test_dfs = {}\n",
    "    file_names = {\"train\": {}, \"test\": {}}\n",
    "    label_df = pd.read_csv(\"labeled_anomalies.csv\")\n",
    "    train_data_path = \"raw_train\" \n",
    "    test_data_path = \"raw_test\" \n",
    "    \n",
    "    for root, _, files in os.walk(train_data_path):\n",
    "        for file in files:\n",
    "            example_path = os.path.join(root, file)\n",
    "            filename = Path(example_path).stem\n",
    "            df = pd.read_csv(example_path)\n",
    "            channel = filename[0]            \n",
    "            if (training_dfs.get(channel) == None):\n",
    "                training_dfs[channel] = []\n",
    "                file_names[\"train\"][channel] = []\n",
    "                training_dfs[channel].append(df)\n",
    "                file_names[\"train\"][channel].append(filename)\n",
    "            else:\n",
    "                training_dfs[channel].append(df)\n",
    "                file_names[\"train\"][channel].append(filename)\n",
    "    \n",
    "    for root, _, files in os.walk(test_data_path):\n",
    "        for file in files:\n",
    "            example_path = os.path.join(root, file)\n",
    "            filename = Path(example_path).stem\n",
    "            df = pd.read_csv(example_path)\n",
    "            channel = filename[0]\n",
    "            if (test_dfs.get(channel) == None):\n",
    "                test_dfs[channel] = []\n",
    "                file_names[\"test\"][channel] = []\n",
    "                test_dfs[channel].append(df)\n",
    "                file_names[\"test\"][channel].append(filename)\n",
    "            else:\n",
    "                test_dfs[channel].append(df)\n",
    "                file_names[\"test\"][channel].append(filename)\n",
    "\n",
    "    return (training_dfs, test_dfs, label_df, file_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b7af7343-fd52-45db-9b3a-0cf2358da275",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_windows(training_dfs, test_dfs, window_size, window_overlap, label_df, file_names):\n",
    "    training_data = {}\n",
    "    test_data = {}\n",
    "    label_data = {}\n",
    "    \n",
    "    for channel in training_dfs.keys():\n",
    "        training_data[channel] = []\n",
    "        for df in training_dfs[channel]: \n",
    "            for i in range(0, len(df), window_overlap):\n",
    "                window = []\n",
    "                if i + window_size > len(df): \n",
    "                    window = df.iloc[-window_size:].to_numpy().tolist()\n",
    "                else: \n",
    "                    window = df.iloc[i:i + window_size].to_numpy().tolist()\n",
    "                np_window = np.array(window)\n",
    "                transposed_window = np_window.T\n",
    "                normal_window = transposed_window.tolist() \n",
    "                training_data[channel].append(normal_window)\n",
    "                \n",
    "    for channel in test_dfs.keys():\n",
    "        test_data[channel] = []\n",
    "        label_data[channel] = []\n",
    "        for i in range(len(test_dfs[channel])):\n",
    "            df = test_dfs[channel][i]\n",
    "            for j in range(0, len(df), window_overlap):\n",
    "                window = []\n",
    "                if j + window_size > len(df): \n",
    "                    window = df.iloc[-window_size:].to_numpy().tolist()\n",
    "                else: \n",
    "                    window = df.iloc[j:j + window_size].to_numpy().tolist()\n",
    "                row_indices = label_df[label_df[\"chan_id\"] == file_names[\"test\"][channel][i]].index.tolist()\n",
    "                \n",
    "                if not row_indices:\n",
    "                    continue\n",
    "\n",
    "                anomaly_sequence = label_df.loc[row_indices[0], 'anomaly_sequences']\n",
    "                anomaly_sequence = ast.literal_eval(anomaly_sequence)\n",
    "                labeled = False\n",
    "                for anomalies in anomaly_sequence:\n",
    "                    if (not(anomalies[1] <= j or anomalies[0] >= j + window_size)) and labeled == False:\n",
    "                        label_data[channel].append(1)\n",
    "                        labeled = True\n",
    "                if labeled == False:\n",
    "                    label_data[channel].append(0)\n",
    "                np_window = np.array(window)\n",
    "                transposed_window = np_window.T\n",
    "                normal_window = transposed_window.tolist() \n",
    "                test_data[channel].append(normal_window)\n",
    "                \n",
    "    return (training_data, test_data, label_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1d0c50c2-a610-488e-8e78-a346d393de6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train:  A shape:  (842, 25, 60)\n",
      "train:  P shape:  (703, 25, 60)\n",
      "train:  F shape:  (432, 25, 60)\n",
      "train:  D shape:  (1445, 25, 60)\n",
      "train:  R shape:  (144, 25, 60)\n",
      "train:  G shape:  (793, 25, 60)\n",
      "train:  T shape:  (431, 25, 60)\n",
      "train:  E shape:  (1867, 25, 60)\n",
      "train:  S shape:  (141, 25, 60)\n",
      "train:  B shape:  (122, 25, 60)\n",
      "test:  E shape:  (5486, 25, 60)\n",
      "test:  T shape:  (1292, 25, 60)\n",
      "test:  G shape:  (2405, 25, 60)\n",
      "test:  D shape:  (4789, 25, 60)\n",
      "test:  A shape:  (3374, 25, 60)\n",
      "test:  F shape:  (1281, 25, 60)\n",
      "test:  P shape:  (2056, 25, 60)\n",
      "test:  B shape:  (403, 25, 60)\n",
      "test:  R shape:  (363, 25, 60)\n",
      "test:  S shape:  (367, 25, 60)\n",
      "label:  E shape:  (5486,)\n",
      "label:  T shape:  (1292,)\n",
      "label:  G shape:  (2405,)\n",
      "label:  D shape:  (4789,)\n",
      "label:  A shape:  (3374,)\n",
      "label:  F shape:  (1281,)\n",
      "label:  P shape:  (2056,)\n",
      "label:  B shape:  (403,)\n",
      "label:  R shape:  (363,)\n",
      "label:  S shape:  (367,)\n"
     ]
    }
   ],
   "source": [
    "window_size = 60 \n",
    "window_overlap = 20\n",
    "training_dfs, test_dfs, label_df, file_names = get_data()\n",
    "\n",
    "X_train_collection, X_test_collection, y_test_collection = create_windows(training_dfs, test_dfs, window_size, window_overlap, label_df, file_names)\n",
    "\n",
    "data = {}\n",
    "os.makedirs(\"data\", exist_ok=True)\n",
    "\n",
    "for channel in X_train_collection:\n",
    "    if data.get(channel) is None:\n",
    "        data[channel] = {}\n",
    "    if data.get(channel).get(\"train\") is None:\n",
    "        X_train = np.array(X_train_collection[channel])\n",
    "        path = f\"data/{channel}/train\"\n",
    "        os.makedirs(path, exist_ok=True)\n",
    "        np.save(path + f\"/{channel}.npy\", X_train)\n",
    "        data[channel][\"train\"] = path + f\"/{channel}.npy\"\n",
    "        print(\"train: \", channel, \"shape: \", X_train.shape)\n",
    "    else:\n",
    "        print(\"Error: duplicate training data sets\")\n",
    "   \n",
    "    \n",
    "for channel in X_test_collection: \n",
    "    if data.get(channel) is None:\n",
    "        continue\n",
    "    if data.get(channel).get(\"test\") is None:\n",
    "        X_test = np.array(X_test_collection[channel])\n",
    "        path = f\"data/{channel}/test\"\n",
    "        os.makedirs(path, exist_ok=True)\n",
    "        np.save(path + f\"/{channel}.npy\", X_test)\n",
    "        data[channel][\"test\"] = path + f\"/{channel}.npy\"\n",
    "        print(\"test: \", channel, \"shape: \", X_test.shape)\n",
    "    else:\n",
    "        print(\"Error: duplicate testing data sets\")\n",
    "   \n",
    "  \n",
    "for channel in y_test_collection:\n",
    "    if data.get(channel) is None:\n",
    "        continue\n",
    "    if data.get(channel).get(\"label\") is None:\n",
    "        y_test = np.array(y_test_collection[channel])\n",
    "        path = f\"data/{channel}/label\"\n",
    "        os.makedirs(path, exist_ok=True)\n",
    "        np.save(path + f\"/{channel}.npy\", y_test)\n",
    "        data[channel][\"label\"] = path + f\"/{channel}.npy\"\n",
    "        print(\"label: \", channel, \"shape: \", y_test.shape)\n",
    "    else:\n",
    "        print(\"Error: duplicate label data sets\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b62abdbd-26c4-4901-b050-32642e436af7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['T', 'G', 'S', 'P', 'D', 'F', 'R', 'A', 'E', 'B']\n"
     ]
    }
   ],
   "source": [
    "channel_names = []\n",
    "\n",
    "for channel in os.listdir(\"data\"):\n",
    "    if os.path.isdir(os.path.join(\"data\", channel)):\n",
    "        channel_names.append(channel)\n",
    "print(channel_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8916e30a-ea28-467c-a281-986881bd9da8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/DAVIDSON/haotaki/.local/lib/python3.10/site-packages/numba/np/ufunc/parallel.py:373: NumbaWarning: \u001b[1mThe TBB threading layer requires TBB version 2021 update 6 or later i.e., TBB_INTERFACE_VERSION >= 12060. Found TBB_INTERFACE_VERSION = 12050. The TBB threading layer is disabled.\u001b[0m\n",
      "  warnings.warn(problem)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train:  T shape:  (431, 9996)\n",
      "test:  T shape:  (1292, 9996)\n",
      "label:  T shape:  (1292,)\n",
      "train:  G shape:  (793, 9996)\n",
      "test:  G shape:  (2405, 9996)\n",
      "label:  G shape:  (2405,)\n",
      "train:  S shape:  (141, 9996)\n",
      "test:  S shape:  (367, 9996)\n",
      "label:  S shape:  (367,)\n",
      "train:  P shape:  (703, 9996)\n",
      "test:  P shape:  (2056, 9996)\n",
      "label:  P shape:  (2056,)\n",
      "train:  D shape:  (1445, 9996)\n",
      "test:  D shape:  (4789, 9996)\n",
      "label:  D shape:  (4789,)\n",
      "train:  F shape:  (432, 9996)\n",
      "test:  F shape:  (1281, 9996)\n",
      "label:  F shape:  (1281,)\n",
      "train:  R shape:  (144, 9996)\n",
      "test:  R shape:  (363, 9996)\n",
      "label:  R shape:  (363,)\n",
      "train:  A shape:  (842, 9996)\n",
      "test:  A shape:  (3374, 9996)\n",
      "label:  A shape:  (3374,)\n",
      "train:  E shape:  (1867, 9996)\n",
      "test:  E shape:  (5486, 9996)\n",
      "label:  E shape:  (5486,)\n",
      "train:  B shape:  (122, 9996)\n",
      "test:  B shape:  (403, 9996)\n",
      "label:  B shape:  (403,)\n"
     ]
    }
   ],
   "source": [
    "transformed_data= {}\n",
    "for channel in channel_names:\n",
    "    transformed_data[channel] = {}\n",
    "    training_data_path = f\"data/{channel}/train/{channel}.npy\"\n",
    "    testing_data_path = f\"data/{channel}/test/{channel}.npy\"\n",
    "    label_data_path = f\"data/{channel}/label/{channel}.npy\"\n",
    "    \n",
    "    X_train = np.load(training_data_path)\n",
    "    X_test = np.load(testing_data_path)\n",
    "    y_test = np.load(label_data_path)\n",
    "\n",
    "    minirocket = MiniRocketMultivariate(n_jobs = 2, random_state = 42) \n",
    "    minirocket.fit(X_train)\n",
    "    X_transform_train = minirocket.transform(X_train)\n",
    "    X_transform_test = minirocket.transform(X_test)\n",
    "\n",
    "    transformed_data[channel][\"train\"] = X_transform_train\n",
    "    print(\"train: \", channel, \"shape: \", X_transform_train.shape)\n",
    "    transformed_data[channel][\"test\"] = X_transform_test\n",
    "    print(\"test: \", channel, \"shape: \", X_transform_test.shape)\n",
    "    transformed_data[channel][\"label\"] = y_test\n",
    "    print(\"label: \", channel, \"shape: \", y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e38d02f6-6973-4871-b93e-2e7fcba2727b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train:  T shape:  (431, 9996)\n",
      "test:  T shape:  (1292, 9996)\n",
      "label:  T shape:  (1292,)\n",
      "train:  G shape:  (793, 9996)\n",
      "test:  G shape:  (2405, 9996)\n",
      "label:  G shape:  (2405,)\n",
      "train:  S shape:  (141, 9996)\n",
      "test:  S shape:  (367, 9996)\n",
      "label:  S shape:  (367,)\n",
      "train:  P shape:  (703, 9996)\n",
      "test:  P shape:  (2056, 9996)\n",
      "label:  P shape:  (2056,)\n",
      "train:  D shape:  (1445, 9996)\n",
      "test:  D shape:  (4789, 9996)\n",
      "label:  D shape:  (4789,)\n",
      "train:  F shape:  (432, 9996)\n",
      "test:  F shape:  (1281, 9996)\n",
      "label:  F shape:  (1281,)\n",
      "train:  R shape:  (144, 9996)\n",
      "test:  R shape:  (363, 9996)\n",
      "label:  R shape:  (363,)\n",
      "train:  A shape:  (842, 9996)\n",
      "test:  A shape:  (3374, 9996)\n",
      "label:  A shape:  (3374,)\n",
      "train:  E shape:  (1867, 9996)\n",
      "test:  E shape:  (5486, 9996)\n",
      "label:  E shape:  (5486,)\n",
      "train:  B shape:  (122, 9996)\n",
      "test:  B shape:  (403, 9996)\n",
      "label:  B shape:  (403,)\n"
     ]
    }
   ],
   "source": [
    "fitted_data = {}\n",
    "\n",
    "for channel in transformed_data: \n",
    "    fitted_data[channel] = {}\n",
    "    X_transform_train = transformed_data[channel][\"train\"]\n",
    "    X_transform_test = transformed_data[channel][\"test\"]\n",
    "    scaler = MinMaxScaler()\n",
    "    scaler.fit(X_transform_train)\n",
    "    X_fit_train = scaler.transform(X_transform_train)\n",
    "    X_fit_test = scaler.transform(X_transform_test)\n",
    "    \n",
    "    fitted_data[channel][\"train\"] = X_fit_train\n",
    "    fitted_data[channel][\"test\"] = X_fit_test\n",
    "    fitted_data[channel][\"label\"] = transformed_data[channel][\"label\"]\n",
    "    print(\"train: \", channel, \"shape: \", X_fit_train.shape)\n",
    "    print(\"test: \", channel, \"shape: \", X_fit_test.shape)\n",
    "    print(\"label: \", channel, \"shape: \", transformed_data[channel][\"label\"].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "d722ab9f-a61f-4f36-8347-a54434153f8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.14628482972136223, 0.021205821205821207, 0.0681198910081744, 0.14348249027237353, 0.22635205679682607, 0.12724434035909446, 0.01928374655647383, 0.16478956727919383, 0.11009843237331389, 0.01488833746898263]\n"
     ]
    }
   ],
   "source": [
    "# performance bad for channels B, R, and S due to their small training data size\n",
    "# nu - controls boundary tightness (Smaller nu → tighter boundary → fewer false positives, Larger nu → looser boundary → higher recall)\n",
    "# threshold\t- converts scores (anomaly / normal)\n",
    "\n",
    "# Large (1000+ windows/channel)\tMostly clean\t0.01 – 0.02\n",
    "# Medium (hundreds of windows)\tMostly clean\t0.02 – 0.05\n",
    "# Small or noisy\tSome anomalies in training\t0.05 – 0.1\n",
    "#tighter nu makes more sense as the training data is supposed to have only normal data - needs confirmation at this point in time \n",
    "\n",
    "anomaly_rate = []\n",
    "for channel in transformed_data: \n",
    "    anomaly_count = 0\n",
    "    for label in fitted_data[channel][\"label\"]:\n",
    "        if label == 1:\n",
    "            anomaly_count += 1\n",
    "    anomaly_rate.append(anomaly_count / len(fitted_data[channel][\"label\"]))\n",
    "    \n",
    "print(anomaly_rate)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "183b7ba3-ab8b-4f27-af59-6786a12b5141",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(threshold, decision_scores):\n",
    "    y_pred = []\n",
    "    for score in decision_scores: \n",
    "        if score < threshold: \n",
    "            y_pred.append(1)\n",
    "        else:\n",
    "            y_pred.append(0)\n",
    "    return np.array(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c299bcd5-4795-4e06-a8de-cf0c38e70a35",
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_class_svm(channel_data, channel):\n",
    "    print(\"channel:\", channel)\n",
    "    clf = OneClassSVM().fit(channel_data[\"train\"])\n",
    "    decision_scores = clf.decision_function(channel_data[\"test\"])\n",
    "    \n",
    "    thresholds = []\n",
    "    for score in decision_scores: \n",
    "        if score < 0:\n",
    "            thresholds.append(score)\n",
    "    \n",
    "    best_f1_score = 0\n",
    "    best_recall_score = 0\n",
    "    best_thresholds = []\n",
    "    best_threshold = 0\n",
    "\n",
    "    # for th in thresholds:\n",
    "    #     y_pred = predict(th, decision_scores)\n",
    "    #     f1 = f1_score(channel_data[\"label\"], y_pred)\n",
    "    #     if (best_f1_score <= f1):\n",
    "    #         best_f1_score = f1\n",
    "    #         best_threshold = th\n",
    "\n",
    "    for th in thresholds:\n",
    "        y_pred = predict(th, decision_scores)\n",
    "        f1 = f1_score(channel_data[\"label\"], y_pred)\n",
    "        recall = recall_score(channel_data[\"label\"], y_pred)\n",
    "        if (best_recall_score <= recall):\n",
    "            best_recall_score = recall\n",
    "            best_thresholds.append(th) \n",
    "    \n",
    "    for th in best_thresholds:\n",
    "        y_pred = predict(th, decision_scores)\n",
    "        f1 = f1_score(channel_data[\"label\"], y_pred)\n",
    "        if (best_f1_score <= f1):\n",
    "            best_f1_score = f1\n",
    "            best_threshold = th\n",
    "    \n",
    "    y_test = channel_data[\"label\"]\n",
    "    y_pred = predict(best_threshold, decision_scores)\n",
    "    print(\"best_threshold: \", best_threshold)\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    precision = precision_score(y_test, y_pred, average='weighted')\n",
    "    print(\"FDR:\", 1 - precision)\n",
    "    c_m = confusion_matrix(y_test, y_pred)\n",
    "    print(c_m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "207f134b-c3af-4e7b-9e60-df31cec0c957",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "channel: T\n",
      "best_threshold:  -0.027457979179303038\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.59      0.68      1103\n",
      "           1       0.09      0.25      0.14       189\n",
      "\n",
      "    accuracy                           0.54      1292\n",
      "   macro avg       0.46      0.42      0.41      1292\n",
      "weighted avg       0.71      0.54      0.60      1292\n",
      "\n",
      "FDR: 0.2864852626864265\n",
      "[[646 457]\n",
      " [142  47]]\n",
      "channel: G\n",
      "best_threshold:  -5.657644072881624\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.76      0.86      2354\n",
      "           1       0.04      0.45      0.07        51\n",
      "\n",
      "    accuracy                           0.76      2405\n",
      "   macro avg       0.51      0.61      0.47      2405\n",
      "weighted avg       0.96      0.76      0.84      2405\n",
      "\n",
      "FDR: 0.03535299951608539\n",
      "[[1800  554]\n",
      " [  28   23]]\n",
      "channel: S\n",
      "best_threshold:  -0.2859636559503791\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.56      0.71       342\n",
      "           1       0.12      0.84      0.21        25\n",
      "\n",
      "    accuracy                           0.58       367\n",
      "   macro avg       0.55      0.70      0.46       367\n",
      "weighted avg       0.92      0.58      0.68       367\n",
      "\n",
      "FDR: 0.07891841698634683\n",
      "[[191 151]\n",
      " [  4  21]]\n",
      "channel: P\n",
      "best_threshold:  -0.09215555038088041\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.35      0.50      1761\n",
      "           1       0.16      0.74      0.26       295\n",
      "\n",
      "    accuracy                           0.40      2056\n",
      "   macro avg       0.52      0.54      0.38      2056\n",
      "weighted avg       0.78      0.40      0.47      2056\n",
      "\n",
      "FDR: 0.2171996116105841\n",
      "[[ 614 1147]\n",
      " [  78  217]]\n",
      "channel: D\n",
      "best_threshold:  -0.0829721582074967\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.60      0.70      3705\n",
      "           1       0.32      0.65      0.43      1084\n",
      "\n",
      "    accuracy                           0.61      4789\n",
      "   macro avg       0.59      0.62      0.56      4789\n",
      "weighted avg       0.73      0.61      0.64      4789\n",
      "\n",
      "FDR: 0.2679499960497369\n",
      "[[2207 1498]\n",
      " [ 381  703]]\n",
      "channel: F\n",
      "best_threshold:  -0.013036751453412876\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.13      0.23      1118\n",
      "           1       0.12      0.82      0.21       163\n",
      "\n",
      "    accuracy                           0.22      1281\n",
      "   macro avg       0.48      0.48      0.22      1281\n",
      "weighted avg       0.74      0.22      0.23      1281\n",
      "\n",
      "FDR: 0.25562013524887206\n",
      "[[147 971]\n",
      " [ 29 134]]\n",
      "channel: R\n",
      "best_threshold:  -23.521180814238708\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.94      0.96       356\n",
      "           1       0.12      0.43      0.19         7\n",
      "\n",
      "    accuracy                           0.93       363\n",
      "   macro avg       0.55      0.68      0.58       363\n",
      "weighted avg       0.97      0.93      0.95       363\n",
      "\n",
      "FDR: 0.028575806477904475\n",
      "[[334  22]\n",
      " [  4   3]]\n",
      "channel: A\n",
      "best_threshold:  -0.00020501814049112\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.41      0.54      2818\n",
      "           1       0.13      0.44      0.20       556\n",
      "\n",
      "    accuracy                           0.41      3374\n",
      "   macro avg       0.46      0.42      0.37      3374\n",
      "weighted avg       0.68      0.41      0.48      3374\n",
      "\n",
      "FDR: 0.321999098421203\n",
      "[[1150 1668]\n",
      " [ 312  244]]\n",
      "channel: E\n",
      "best_threshold:  -3.755458027391512\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.51      0.66      4882\n",
      "           1       0.18      0.85      0.29       604\n",
      "\n",
      "    accuracy                           0.55      5486\n",
      "   macro avg       0.57      0.68      0.48      5486\n",
      "weighted avg       0.88      0.55      0.62      5486\n",
      "\n",
      "FDR: 0.12156471090219012\n",
      "[[2476 2406]\n",
      " [  89  515]]\n",
      "channel: B\n",
      "best_threshold:  -1.6053533613558102e-08\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.57      0.72       397\n",
      "           1       0.03      1.00      0.07         6\n",
      "\n",
      "    accuracy                           0.57       403\n",
      "   macro avg       0.52      0.78      0.39       403\n",
      "weighted avg       0.99      0.57      0.71       403\n",
      "\n",
      "FDR: 0.014386483396994443\n",
      "[[225 172]\n",
      " [  0   6]]\n"
     ]
    }
   ],
   "source": [
    "for channel in fitted_data:\n",
    "    one_class_svm(fitted_data[channel], channel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "39100882-1db0-41d8-a761-c0f45e196a1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(threshold, decision_scores):\n",
    "    y_pred = []\n",
    "    for score in decision_scores: \n",
    "        if score < threshold: \n",
    "            y_pred.append(1)\n",
    "        else:\n",
    "            y_pred.append(0)\n",
    "    return np.array(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "5f7f7be4-5040-4199-acf3-dc633f52fba9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def isolation_forest_default(channel_data, channel):\n",
    "    print(\"channel:\", channel)\n",
    "    #contamination=0\n",
    "    clf = IsolationForest(contamination=0.5, random_state=42, n_jobs=-1).fit(channel_data[\"train\"])\n",
    "    # decision_scores = clf.decision_function(channel_data[\"test\"])\n",
    "    \n",
    "    # thresholds = []\n",
    "    # for score in decision_scores: \n",
    "    #     if score < 0:\n",
    "    #         thresholds.append(score)\n",
    "    \n",
    "    # best_f1_score = 0\n",
    "    # best_recall_score = 0\n",
    "    # best_thresholds = []\n",
    "    # best_threshold = 0\n",
    "\n",
    "    # # for th in thresholds:\n",
    "    # #     y_pred = predict(th, decision_scores)\n",
    "    # #     f1 = f1_score(channel_data[\"label\"], y_pred)\n",
    "    # #     if (best_f1_score <= f1):\n",
    "    # #         best_f1_score = f1\n",
    "    # #         best_threshold = th\n",
    "\n",
    "    # for th in thresholds:\n",
    "    #     y_pred = predict(th, decision_scores)\n",
    "    #     f1 = f1_score(channel_data[\"label\"], y_pred)\n",
    "    #     recall = recall_score(channel_data[\"label\"], y_pred)\n",
    "    #     if (best_recall_score <= recall):\n",
    "    #         best_recall_score = recall\n",
    "    #         best_thresholds.append(th) \n",
    "    \n",
    "    # for th in best_thresholds:\n",
    "    #     y_pred = predict(th, decision_scores)\n",
    "    #     f1 = f1_score(channel_data[\"label\"], y_pred)\n",
    "    #     if (best_f1_score <= f1):\n",
    "    #         best_f1_score = f1\n",
    "    #         best_threshold = th\n",
    "    \n",
    "    y_test = channel_data[\"label\"]\n",
    "    # y_pred = predict(best_threshold, decision_scores)\n",
    "    raw_y_pred = clf.predict(channel_data[\"test\"])\n",
    "    y_pred = []\n",
    "    for y in raw_y_pred:\n",
    "        if y == -1:\n",
    "            y_pred.append(1)\n",
    "        else:\n",
    "            y_pred.append(0)\n",
    "            \n",
    "    # print(\"best_threshold: \", best_threshold)\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    precision = precision_score(y_test, y_pred, average='weighted')\n",
    "    print(\"FDR:\", 1 - precision)\n",
    "    c_m = confusion_matrix(y_test, y_pred)\n",
    "    print(c_m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "36fafb8e-9f0e-4cd6-b18d-d1b4902bda29",
   "metadata": {},
   "outputs": [],
   "source": [
    "def isolation_forest_manual(channel_data, channel):\n",
    "    print(\"channel:\", channel)\n",
    "    #contamination=0\n",
    "    clf = IsolationForest(contamination=0.5, random_state=42, n_jobs=-1).fit(channel_data[\"train\"])\n",
    "    decision_scores = clf.decision_function(channel_data[\"test\"])\n",
    "    \n",
    "    thresholds = []\n",
    "    for score in decision_scores: \n",
    "        if score < 0:\n",
    "            thresholds.append(score)\n",
    "    \n",
    "    best_f1_score = 0\n",
    "    best_recall_score = 0\n",
    "    best_thresholds = []\n",
    "    best_threshold = 0\n",
    "\n",
    "    # for th in thresholds:\n",
    "    #     y_pred = predict(th, decision_scores)\n",
    "    #     f1 = f1_score(channel_data[\"label\"], y_pred)\n",
    "    #     if (best_f1_score <= f1):\n",
    "    #         best_f1_score = f1\n",
    "    #         best_threshold = th\n",
    "\n",
    "    for th in thresholds:\n",
    "        y_pred = predict(th, decision_scores)\n",
    "        f1 = f1_score(channel_data[\"label\"], y_pred)\n",
    "        recall = recall_score(channel_data[\"label\"], y_pred)\n",
    "        if (best_recall_score <= recall):\n",
    "            best_recall_score = recall\n",
    "            best_thresholds.append(th) \n",
    "    \n",
    "    for th in best_thresholds:\n",
    "        y_pred = predict(th, decision_scores)\n",
    "        f1 = f1_score(channel_data[\"label\"], y_pred)\n",
    "        if (best_f1_score <= f1):\n",
    "            best_f1_score = f1\n",
    "            best_threshold = th\n",
    "    \n",
    "    y_test = channel_data[\"label\"]\n",
    "    y_pred = predict(best_threshold, decision_scores)\n",
    "    # raw_y_pred = clf.predict(channel_data[\"test\"])\n",
    "    # y_pred = []\n",
    "    # for y in raw_y_pred:\n",
    "    #     if y == -1:\n",
    "    #         y_pred.append(1)\n",
    "    #     else:\n",
    "    #         y_pred.append(0)\n",
    "            \n",
    "    print(\"best_threshold: \", best_threshold)\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    precision = precision_score(y_test, y_pred, average='weighted')\n",
    "    print(\"FDR:\", 1 - precision)\n",
    "    c_m = confusion_matrix(y_test, y_pred)\n",
    "    print(c_m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7003185-2129-4e99-8fa6-bd5323a3b1e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "channel: T\n",
      "best_threshold:  -0.00013722055087511675\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.56      0.69      1103\n",
      "           1       0.19      0.60      0.29       189\n",
      "\n",
      "    accuracy                           0.57      1292\n",
      "   macro avg       0.54      0.58      0.49      1292\n",
      "weighted avg       0.79      0.57      0.63      1292\n",
      "\n",
      "FDR: 0.21047857950240767\n",
      "[[620 483]\n",
      " [ 75 114]]\n",
      "channel: G\n",
      "best_threshold:  -0.00023553628446976171\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.54      0.70      2354\n",
      "           1       0.02      0.51      0.04        51\n",
      "\n",
      "    accuracy                           0.54      2405\n",
      "   macro avg       0.50      0.53      0.37      2405\n",
      "weighted avg       0.96      0.54      0.68      2405\n",
      "\n",
      "FDR: 0.03954476717361499\n",
      "[[1274 1080]\n",
      " [  25   26]]\n",
      "channel: S\n",
      "best_threshold:  -0.017497584179967884\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.69      0.80       342\n",
      "           1       0.12      0.60      0.21        25\n",
      "\n",
      "    accuracy                           0.69       367\n",
      "   macro avg       0.54      0.65      0.51       367\n",
      "weighted avg       0.90      0.69      0.76       367\n",
      "\n",
      "FDR: 0.09733284426744926\n",
      "[[237 105]\n",
      " [ 10  15]]\n",
      "channel: P\n",
      "best_threshold:  -0.00020906517041768824\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.68      0.76      1761\n",
      "           1       0.17      0.41      0.24       295\n",
      "\n",
      "    accuracy                           0.64      2056\n",
      "   macro avg       0.52      0.54      0.50      2056\n",
      "weighted avg       0.77      0.64      0.69      2056\n",
      "\n",
      "FDR: 0.2284915765413308\n",
      "[[1189  572]\n",
      " [ 175  120]]\n",
      "channel: D\n",
      "best_threshold:  -2.5170898582949075e-05\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.59      0.68      3705\n",
      "           1       0.27      0.50      0.35      1084\n",
      "\n",
      "    accuracy                           0.57      4789\n",
      "   macro avg       0.53      0.55      0.51      4789\n",
      "weighted avg       0.68      0.57      0.61      4789\n",
      "\n",
      "FDR: 0.31873769832772925\n",
      "[[2189 1516]\n",
      " [ 537  547]]\n",
      "channel: F\n",
      "best_threshold:  -0.12420983158090593\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.98      0.92      1118\n",
      "           1       0.16      0.02      0.04       163\n",
      "\n",
      "    accuracy                           0.86      1281\n",
      "   macro avg       0.52      0.50      0.48      1281\n",
      "weighted avg       0.78      0.86      0.81      1281\n",
      "\n",
      "FDR: 0.21736944166828265\n",
      "[[1097   21]\n",
      " [ 159    4]]\n",
      "channel: R\n",
      "best_threshold:  -0.007418045938179296\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.94      0.96       356\n",
      "           1       0.12      0.43      0.19         7\n",
      "\n",
      "    accuracy                           0.93       363\n",
      "   macro avg       0.55      0.68      0.58       363\n",
      "weighted avg       0.97      0.93      0.95       363\n",
      "\n",
      "FDR: 0.028575806477904475\n",
      "[[334  22]\n",
      " [  4   3]]\n",
      "channel: A\n",
      "best_threshold:  -0.007742067503208716\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.62      0.69      2818\n",
      "           1       0.02      0.03      0.02       556\n",
      "\n",
      "    accuracy                           0.53      3374\n",
      "   macro avg       0.39      0.33      0.36      3374\n",
      "weighted avg       0.64      0.53      0.58      3374\n",
      "\n",
      "FDR: 0.357316128214611\n",
      "[[1758 1060]\n",
      " [ 537   19]]\n",
      "channel: E\n"
     ]
    }
   ],
   "source": [
    "for channel in fitted_data:\n",
    "    isolation_forest_manual(fitted_data[channel], channel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b35845d8-e200-4709-8440-4ce26fc5e68a",
   "metadata": {},
   "outputs": [],
   "source": [
    "for channel in fitted_data:\n",
    "    isolation_forest_default(fitted_data[channel], channel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baa41085-279e-46b1-b001-274dd234df28",
   "metadata": {},
   "outputs": [],
   "source": [
    "#implement KNN\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b03baf5-f289-4733-9415-955e066d63a9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10",
   "language": "python",
   "name": "python-3.10"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
